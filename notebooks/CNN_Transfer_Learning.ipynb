{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Transfer Learning for Visual Emotion Recognition\n",
    "\n",
    "This notebook demonstrates how to implement transfer learning with CNN networks for visual emotion recognition. We'll use a pre-trained VGG16 model and fine-tune it for our emotion classification task.\n",
    "\n",
    "## What is Transfer Learning?\n",
    "Transfer learning is a machine learning technique where we use a model that has been trained on one task and adapt it for a related task. In our case, we'll use a CNN pre-trained on ImageNet and adapt it for emotion recognition.\n",
    "\n",
    "## Benefits of Transfer Learning:\n",
    "1. **Faster training**: We start with pre-trained weights instead of random initialization\n",
    "2. **Better performance**: Especially when we have limited training data\n",
    "3. **Lower computational requirements**: Less training time needed\n",
    "4. **Proven feature extractors**: Pre-trained networks have learned robust low-level features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "# Sklearn for metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Preparation\n",
    "\n",
    "First, let's set up our data paths and load the dataset splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths (modify these if running locally)\n",
    "PROJECT_ROOT = Path('/home/runner/work/ann-visual-emotion/ann-visual-emotion')\n",
    "CSV_TRAIN = PROJECT_ROOT / 'data/processed/EmoSet_splits/train.csv'\n",
    "CSV_VAL = PROJECT_ROOT / 'data/processed/EmoSet_splits/val.csv'\n",
    "CSV_TEST = PROJECT_ROOT / 'data/processed/EmoSet_splits/test.csv'\n",
    "LABEL_MAP_PATH = PROJECT_ROOT / 'data/processed/EmoSet_splits/label_map.json'\n",
    "DATA_DIR = PROJECT_ROOT / 'data/raw/EmoSet'\n",
    "\n",
    "# Check if files exist\n",
    "print(\"Checking data files...\")\n",
    "for path in [CSV_TRAIN, CSV_VAL, CSV_TEST, LABEL_MAP_PATH]:\n",
    "    if path.exists():\n",
    "        print(f\"✓ Found: {path}\")\n",
    "    else:\n",
    "        print(f\"✗ Missing: {path}\")\n",
    "\n",
    "# Load label map if it exists\n",
    "if LABEL_MAP_PATH.exists():\n",
    "    with open(LABEL_MAP_PATH, 'r') as f:\n",
    "        label_map = json.load(f)\n",
    "    num_classes = len(label_map)\n",
    "    print(f'Number of emotion classes: {num_classes}')\n",
    "    print(f'Emotion classes: {list(label_map.keys())}')\n",
    "else:\n",
    "    # Create a dummy label map for testing\n",
    "    label_map = {'anger': 0, 'disgust': 1, 'fear': 2, 'happiness': 3, 'sadness': 4, 'surprise': 5, 'neutral': 6}\n",
    "    num_classes = len(label_map)\n",
    "    print(f'Using dummy label map with {num_classes} classes: {list(label_map.keys())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Custom Dataset Class\n",
    "\n",
    "We'll create a custom dataset class that handles both grayscale and RGB images for transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom dataset class for emotion recognition.\n",
    "    Supports both grayscale and RGB images for transfer learning.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, root_dir, transform=None, label_map=None, rgb=True):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataframe: pandas DataFrame with image paths and labels\n",
    "            root_dir: Root directory containing images\n",
    "            transform: Optional transform to be applied on images\n",
    "            label_map: Dictionary mapping emotion names to indices\n",
    "            rgb: If True, convert grayscale images to RGB for pre-trained models\n",
    "        \"\"\"\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map\n",
    "        self.rgb = rgb\n",
    "        \n",
    "        # Auto-detect column names\n",
    "        possible_path_cols = [c for c in self.df.columns if 'path' in c.lower() or 'file' in c.lower() or 'image' in c.lower()]\n",
    "        self.path_col = possible_path_cols[0] if possible_path_cols else self.df.columns[0]\n",
    "        \n",
    "        possible_label_cols = [c for c in self.df.columns if 'label' in c.lower() or 'class' in c.lower() or 'emotion' in c.lower()]\n",
    "        self.label_col = possible_label_cols[0] if possible_label_cols else self.df.columns[1]\n",
    "        \n",
    "        print(f\"Using columns - Path: '{self.path_col}', Label: '{self.label_col}'\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        rel_path = row[self.path_col]\n",
    "        label = row[self.label_col]\n",
    "        \n",
    "        # Convert label to index if needed\n",
    "        if self.label_map and isinstance(label, str):\n",
    "            label_idx = self.label_map[label]\n",
    "        else:\n",
    "            label_idx = int(label)\n",
    "        \n",
    "        # Load image\n",
    "        img_path = self.root_dir / rel_path\n",
    "        \n",
    "        try:\n",
    "            if self.rgb:\n",
    "                # Load as RGB for pre-trained models\n",
    "                image = Image.open(img_path).convert('RGB')\n",
    "            else:\n",
    "                # Load as grayscale\n",
    "                image = Image.open(img_path).convert('L')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {img_path}: {e}\")\n",
    "            # Return a dummy image in case of error\n",
    "            if self.rgb:\n",
    "                image = Image.new('RGB', (48, 48), color='black')\n",
    "            else:\n",
    "                image = Image.new('L', (48, 48), color='black')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Transforms for Transfer Learning\n",
    "\n",
    "For transfer learning with pre-trained models, we need to:\n",
    "1. Resize images to the expected input size (224x224 for VGG)\n",
    "2. Normalize with ImageNet statistics\n",
    "3. Apply data augmentation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageNet normalization values (important for transfer learning!)\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Input size for VGG models\n",
    "INPUT_SIZE = 224\n",
    "\n",
    "# Define transforms for training (with data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "# Define transforms for validation/testing (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])\n",
    "\n",
    "print(\"Data transforms created:\")\n",
    "print(f\"- Input size: {INPUT_SIZE}x{INPUT_SIZE}\")\n",
    "print(f\"- ImageNet normalization: mean={IMAGENET_MEAN}, std={IMAGENET_STD}\")\n",
    "print(f\"- Training augmentations: RandomHorizontalFlip, RandomRotation, ColorJitter, RandomAffine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy datasets if actual data files don't exist\n",
    "if not all(path.exists() for path in [CSV_TRAIN, CSV_VAL, CSV_TEST]):\n",
    "    print(\"Creating dummy datasets for demonstration...\")\n",
    "    \n",
    "    # Create dummy data\n",
    "    dummy_data = {\n",
    "        'image_path': [f'dummy_{i}.jpg' for i in range(100)],\n",
    "        'emotion': np.random.choice(list(label_map.keys()), 100)\n",
    "    }\n",
    "    \n",
    "    train_df = pd.DataFrame(dummy_data)\n",
    "    val_df = pd.DataFrame(dummy_data)\n",
    "    test_df = pd.DataFrame(dummy_data)\n",
    "    \n",
    "    print(\"Using dummy datasets (replace with actual data loading when available)\")\n",
    "    \n",
    "else:\n",
    "    # Load actual datasets\n",
    "    print(\"Loading actual datasets...\")\n",
    "    train_df = pd.read_csv(CSV_TRAIN)\n",
    "    val_df = pd.read_csv(CSV_VAL)\n",
    "    test_df = pd.read_csv(CSV_TEST)\n",
    "\n",
    "print(f\"Dataset sizes:\")\n",
    "print(f\"- Training: {len(train_df)}\")\n",
    "print(f\"- Validation: {len(val_df)}\")\n",
    "print(f\"- Testing: {len(test_df)}\")\n",
    "\n",
    "# Create datasets (using RGB for transfer learning)\n",
    "train_dataset = EmotionDataset(train_df, DATA_DIR, transform=train_transform, \n",
    "                              label_map=label_map, rgb=True)\n",
    "val_dataset = EmotionDataset(val_df, DATA_DIR, transform=val_transform, \n",
    "                            label_map=label_map, rgb=True)\n",
    "test_dataset = EmotionDataset(test_df, DATA_DIR, transform=val_transform, \n",
    "                             label_map=label_map, rgb=True)\n",
    "\n",
    "# Create data loaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: CNN Transfer Learning Model\n",
    "\n",
    "Now we'll create our transfer learning model using a pre-trained VGG16 network.\n",
    "\n",
    "### Transfer Learning Strategies:\n",
    "1. **Feature Extraction**: Freeze pre-trained layers, only train classifier\n",
    "2. **Fine-tuning**: Train all layers with very small learning rate\n",
    "3. **Gradual unfreezing**: Start with frozen layers, gradually unfreeze\n",
    "\n",
    "We'll implement strategy #2 (fine-tuning) as it typically gives the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNTransferLearning(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN Transfer Learning model using pre-trained VGG16 backbone.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes, backbone='vgg16', pretrained=True, freeze_backbone=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_classes: Number of emotion classes\n",
    "            backbone: Pre-trained model to use ('vgg16', 'vgg19', 'alexnet')\n",
    "            pretrained: Whether to use pre-trained weights\n",
    "            freeze_backbone: Whether to freeze backbone weights\n",
    "        \"\"\"\n",
    "        super(CNNTransferLearning, self).__init__()\n",
    "        \n",
    "        self.backbone_name = backbone\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Load pre-trained backbone\n",
    "        if backbone == 'vgg16':\n",
    "            self.backbone = models.vgg16(pretrained=pretrained)\n",
    "            backbone_out_features = 25088  # VGG16 feature output size\n",
    "        elif backbone == 'vgg19':\n",
    "            self.backbone = models.vgg19(pretrained=pretrained)\n",
    "            backbone_out_features = 25088  # VGG19 feature output size\n",
    "        elif backbone == 'alexnet':\n",
    "            self.backbone = models.alexnet(pretrained=pretrained)\n",
    "            backbone_out_features = 9216   # AlexNet feature output size\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
    "        \n",
    "        # Remove the original classifier\n",
    "        if backbone in ['vgg16', 'vgg19']:\n",
    "            self.features = self.backbone.features\n",
    "            self.avgpool = self.backbone.avgpool\n",
    "        elif backbone == 'alexnet':\n",
    "            self.features = self.backbone.features\n",
    "            self.avgpool = self.backbone.avgpool\n",
    "        \n",
    "        # Freeze backbone if requested\n",
    "        if freeze_backbone:\n",
    "            for param in self.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(f\"Backbone ({backbone}) weights frozen\")\n",
    "        else:\n",
    "            print(f\"Backbone ({backbone}) weights will be fine-tuned\")\n",
    "        \n",
    "        # Create custom classifier for emotion recognition\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(backbone_out_features, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Initialize classifier weights\n",
    "        self._initialize_classifier()\n",
    "        \n",
    "        print(f\"Model created:\")\n",
    "        print(f\"- Backbone: {backbone} (pretrained={pretrained})\")\n",
    "        print(f\"- Frozen: {freeze_backbone}\")\n",
    "        print(f\"- Output classes: {num_classes}\")\n",
    "    \n",
    "    def _initialize_classifier(self):\n",
    "        \"\"\"Initialize classifier weights using Xavier initialization.\"\"\"\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Extract features using backbone\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Classify\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze backbone layers for fine-tuning.\"\"\"\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"Backbone layers unfrozen for fine-tuning\")\n",
    "    \n",
    "    def freeze_backbone(self):\n",
    "        \"\"\"Freeze backbone layers.\"\"\"\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        print(\"Backbone layers frozen\")\n",
    "    \n",
    "    def get_num_params(self):\n",
    "        \"\"\"Get number of trainable parameters.\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Create the transfer learning model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING CNN TRANSFER LEARNING MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = CNNTransferLearning(\n",
    "    num_classes=num_classes,\n",
    "    backbone='vgg16',\n",
    "    pretrained=True,\n",
    "    freeze_backbone=False  # We'll do fine-tuning\n",
    ").to(device)\n",
    "\n",
    "print(f\"\\nModel has {model.get_num_params():,} trainable parameters\")\n",
    "print(f\"Model moved to device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Training Setup\n",
    "\n",
    "For transfer learning, we need to use different learning rates:\n",
    "- Smaller learning rate for pre-trained layers (if unfrozen)\n",
    "- Regular learning rate for new classifier layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer with different learning rates for backbone and classifier\n",
    "backbone_lr = 1e-5  # Very small LR for pre-trained layers\n",
    "classifier_lr = 1e-3  # Regular LR for new layers\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.features.parameters(), 'lr': backbone_lr},\n",
    "    {'params': model.classifier.parameters(), 'lr': classifier_lr}\n",
    "], weight_decay=1e-4)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "\n",
    "print(f\"Training setup:\")\n",
    "print(f\"- Loss function: CrossEntropyLoss\")\n",
    "print(f\"- Optimizer: Adam\")\n",
    "print(f\"- Backbone LR: {backbone_lr}\")\n",
    "print(f\"- Classifier LR: {classifier_lr}\")\n",
    "print(f\"- Weight decay: 1e-4\")\n",
    "print(f\"- Scheduler: StepLR (step=10, gamma=0.5)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Training Functions\n",
    "\n",
    "Let's create training and validation functions with proper progress tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if batch_idx % 100 == 0 and batch_idx > 0:\n",
    "            print(f'    Batch {batch_idx}/{len(train_loader)}: '\n",
    "                  f'Loss = {running_loss/(batch_idx+1):.4f}, '\n",
    "                  f'Acc = {100.*correct/total:.2f}%')\n",
    "    \n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "            \n",
    "            # Store predictions for detailed analysis\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_targets\n",
    "\n",
    "print(\"Training and validation functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, \n",
    "                device, num_epochs=30, patience=5, save_path='best_cnn_transfer_model.pth'):\n",
    "    \"\"\"\n",
    "    Train the model with early stopping.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"STARTING TRAINING - CNN TRANSFER LEARNING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Epochs: {num_epochs}, Patience: {patience}\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print()\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Training phase\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "        \n",
    "        # Validation phase\n",
    "        val_loss, val_acc, _, _ = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Current LR: {optimizer.param_groups[0]['lr']:.2e} (backbone), {optimizer.param_groups[1]['lr']:.2e} (classifier)\")\n",
    "        \n",
    "        # Check for improvement\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'train_losses': train_losses,\n",
    "                'val_losses': val_losses,\n",
    "                'train_accuracies': train_accuracies,\n",
    "                'val_accuracies': val_accuracies\n",
    "            }, save_path)\n",
    "            print(f\"✓ New best model saved! Val Acc: {best_val_acc:.2f}%\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"No improvement. Patience: {patience_counter}/{patience}\")\n",
    "        \n",
    "        print()\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "    \n",
    "    print(f\"Training completed!\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }\n",
    "\n",
    "print(\"Training function defined. Ready to start training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Start Training\n",
    "\n",
    "Note: If running with dummy data, this will not produce meaningful results. Replace with actual data for real training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have actual data or dummy data\n",
    "if DATA_DIR.exists() and any(DATA_DIR.iterdir()):\n",
    "    print(\"Starting training with actual data...\")\n",
    "    EPOCHS = 20\n",
    "else:\n",
    "    print(\"Using dummy data - training for demonstration only...\")\n",
    "    EPOCHS = 3  # Shorter training for demo\n",
    "\n",
    "# Start training\n",
    "training_history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=EPOCHS,\n",
    "    patience=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Plot Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Plot training and validation metrics.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    ax1.plot(history['train_losses'], label='Training Loss', marker='o')\n",
    "    ax1.plot(history['val_losses'], label='Validation Loss', marker='s')\n",
    "    ax1.set_title('Training and Validation Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot accuracies\n",
    "    ax2.plot(history['train_accuracies'], label='Training Accuracy', marker='o')\n",
    "    ax2.plot(history['val_accuracies'], label='Validation Accuracy', marker='s')\n",
    "    ax2.set_title('Training and Validation Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Training Summary:\")\n",
    "    print(f\"- Final Training Loss: {history['train_losses'][-1]:.4f}\")\n",
    "    print(f\"- Final Validation Loss: {history['val_losses'][-1]:.4f}\")\n",
    "    print(f\"- Final Training Accuracy: {history['train_accuracies'][-1]:.2f}%\")\n",
    "    print(f\"- Final Validation Accuracy: {history['val_accuracies'][-1]:.2f}%\")\n",
    "    print(f\"- Best Validation Accuracy: {history['best_val_acc']:.2f}%\")\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(training_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Load Best Model and Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "if Path('best_cnn_transfer_model.pth').exists():\n",
    "    checkpoint = torch.load('best_cnn_transfer_model.pth', map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    print(f\"Loaded best model from epoch {checkpoint['epoch']} with val acc: {checkpoint['best_val_acc']:.2f}%\")\n",
    "else:\n",
    "    print(\"No saved model found, using current model state\")\n",
    "\n",
    "# Evaluate on test set\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "test_loss, test_acc, test_predictions, test_targets = validate_epoch(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"Test Results:\")\n",
    "print(f\"- Test Loss: {test_loss:.4f}\")\n",
    "print(f\"- Test Accuracy: {test_acc:.2f}%\")\n",
    "\n",
    "# Detailed classification report\n",
    "if len(set(test_targets)) > 1:  # Only if we have multiple classes\n",
    "    print(\"\\nClassification Report:\")\n",
    "    emotion_names = list(label_map.keys())\n",
    "    report = classification_report(test_targets, test_predictions, \n",
    "                                 target_names=emotion_names, \n",
    "                                 zero_division=0)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 13: Visualize Results - Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, class_names, title='Confusion Matrix'):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Predicted Emotion')\n",
    "    plt.ylabel('True Emotion')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print accuracy per class\n",
    "    print(\"\\nPer-class Accuracy:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_correct = cm[i, i]\n",
    "        class_total = cm[i, :].sum()\n",
    "        if class_total > 0:\n",
    "            acc = 100 * class_correct / class_total\n",
    "            print(f\"- {class_name}: {acc:.2f}% ({class_correct}/{class_total})\")\n",
    "\n",
    "# Plot confusion matrix if we have predictions\n",
    "if len(set(test_targets)) > 1:\n",
    "    emotion_names = list(label_map.keys())\n",
    "    plot_confusion_matrix(test_targets, test_predictions, emotion_names, \n",
    "                         'CNN Transfer Learning - Test Set Confusion Matrix')\n",
    "else:\n",
    "    print(\"Skipping confusion matrix (insufficient data/classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 14: Model Comparison and Analysis\n",
    "\n",
    "Let's compare our transfer learning CNN with the original baseline CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ANALYSIS AND COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model parameters\n",
    "print(f\"\\n1. MODEL ARCHITECTURE:\")\n",
    "print(f\"   - Transfer Learning CNN (VGG16 backbone)\")\n",
    "print(f\"   - Total parameters: {model.get_num_params():,}\")\n",
    "print(f\"   - Input size: {INPUT_SIZE}x{INPUT_SIZE}x3 (RGB)\")\n",
    "print(f\"   - Output classes: {num_classes}\")\n",
    "\n",
    "# Performance summary\n",
    "print(f\"\\n2. PERFORMANCE SUMMARY:\")\n",
    "if 'training_history' in locals():\n",
    "    print(f\"   - Best Validation Accuracy: {training_history['best_val_acc']:.2f}%\")\n",
    "    print(f\"   - Final Test Accuracy: {test_acc:.2f}%\")\n",
    "    print(f\"   - Training Epochs: {len(training_history['train_losses'])}\")\n",
    "\n",
    "# Transfer Learning Benefits\n",
    "print(f\"\\n3. TRANSFER LEARNING BENEFITS:\")\n",
    "print(f\"   ✓ Pre-trained features: Learned from ImageNet (1.2M images)\")\n",
    "print(f\"   ✓ Faster convergence: Starts with meaningful weights\")\n",
    "print(f\"   ✓ Better generalization: Robust low-level feature extraction\")\n",
    "print(f\"   ✓ Less overfitting: Pre-trained features are well-regularized\")\n",
    "\n",
    "print(f\"\\n4. KEY DIFFERENCES FROM BASELINE CNN:\")\n",
    "print(f\"   - Uses pre-trained VGG16 backbone vs. random initialization\")\n",
    "print(f\"   - RGB input (224x224) vs. Grayscale (48x48)\")\n",
    "print(f\"   - ImageNet normalization vs. simple normalization\")\n",
    "print(f\"   - Transfer learning strategy vs. training from scratch\")\n",
    "print(f\"   - Different learning rates for backbone vs. classifier\")\n",
    "\n",
    "print(f\"\\n5. TRAINING STRATEGY USED:\")\n",
    "print(f\"   - Fine-tuning: All layers trainable\")\n",
    "print(f\"   - Backbone LR: {backbone_lr} (very small)\")\n",
    "print(f\"   - Classifier LR: {classifier_lr} (regular)\")\n",
    "print(f\"   - Data augmentation: Rotation, flip, color jitter, affine\")\n",
    "print(f\"   - Early stopping with patience={5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 15: Save Final Model for Production\n",
    "\n",
    "Let's save our model in a format that can be easily loaded for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save complete model information\n",
    "final_model_info = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'model_config': {\n",
    "        'num_classes': num_classes,\n",
    "        'backbone': 'vgg16',\n",
    "        'input_size': INPUT_SIZE,\n",
    "        'pretrained': True,\n",
    "        'freeze_backbone': False\n",
    "    },\n",
    "    'label_map': label_map,\n",
    "    'transforms': {\n",
    "        'mean': IMAGENET_MEAN,\n",
    "        'std': IMAGENET_STD,\n",
    "        'input_size': INPUT_SIZE\n",
    "    },\n",
    "    'training_info': {\n",
    "        'final_test_acc': test_acc,\n",
    "        'backbone_lr': backbone_lr,\n",
    "        'classifier_lr': classifier_lr\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(final_model_info, 'cnn_transfer_learning_final.pth')\n",
    "print(\"✓ Final model saved as 'cnn_transfer_learning_final.pth'\")\n",
    "\n",
    "# Create a simple inference function\n",
    "def create_inference_function():\n",
    "    \"\"\"\n",
    "    Create a simple inference function that can be used in production.\n",
    "    \"\"\"\n",
    "    inference_code = '''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "\n",
    "def load_emotion_model(model_path):\n",
    "    \"\"\"Load the trained emotion recognition model.\"\"\"\n",
    "    checkpoint = torch.load(model_path, map_location='cpu')\n",
    "    \n",
    "    # Recreate model architecture\n",
    "    model = CNNTransferLearning(\n",
    "        num_classes=checkpoint['model_config']['num_classes'],\n",
    "        backbone=checkpoint['model_config']['backbone'],\n",
    "        pretrained=False  # We're loading trained weights\n",
    "    )\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    \n",
    "    # Create transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((checkpoint['transforms']['input_size'], \n",
    "                          checkpoint['transforms']['input_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=checkpoint['transforms']['mean'], \n",
    "                           std=checkpoint['transforms']['std'])\n",
    "    ])\n",
    "    \n",
    "    return model, transform, checkpoint['label_map']\n",
    "\n",
    "def predict_emotion(model, transform, label_map, image_path):\n",
    "    \"\"\"Predict emotion from image.\"\"\"\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image).unsqueeze(0)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    # Convert to emotion name\n",
    "    emotion_names = {v: k for k, v in label_map.items()}\n",
    "    predicted_emotion = emotion_names[predicted_class]\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    return predicted_emotion, confidence, probabilities[0].numpy()\n",
    "'''\n",
    "    \n",
    "    with open('emotion_inference.py', 'w') as f:\n",
    "        f.write(inference_code)\n",
    "    \n",
    "    print(\"✓ Inference code saved as 'emotion_inference.py'\")\n",
    "\n",
    "create_inference_function()\n",
    "\n",
    "print(\"\\n✓ Model deployment ready!\")\n",
    "print(\"Files created:\")\n",
    "print(\"- cnn_transfer_learning_final.pth (complete model)\")\n",
    "print(\"- emotion_inference.py (inference functions)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: CNN Transfer Learning Implementation\n",
    "\n",
    "### What We've Accomplished:\n",
    "\n",
    "1. **Transfer Learning Setup**: Implemented CNN transfer learning using VGG16 backbone pre-trained on ImageNet\n",
    "\n",
    "2. **Architecture**: \n",
    "   - Pre-trained VGG16 feature extractor\n",
    "   - Custom classifier head for emotion recognition\n",
    "   - Support for RGB images (224×224)\n",
    "\n",
    "3. **Training Strategy**:\n",
    "   - Fine-tuning approach with different learning rates\n",
    "   - ImageNet normalization for compatibility\n",
    "   - Data augmentation for better generalization\n",
    "   - Early stopping to prevent overfitting\n",
    "\n",
    "4. **Key Benefits Over Baseline CNN**:\n",
    "   - ✅ **Faster Convergence**: Pre-trained weights provide good starting point\n",
    "   - ✅ **Better Feature Learning**: Robust low-level features from ImageNet\n",
    "   - ✅ **Improved Generalization**: Less prone to overfitting\n",
    "   - ✅ **State-of-the-art Architecture**: Proven CNN design\n",
    "\n",
    "### Transfer Learning Strategies Implemented:\n",
    "\n",
    "1. **Feature Extraction** (freezing backbone)\n",
    "2. **Fine-tuning** (training all layers with different LRs)\n",
    "3. **Gradual unfreezing** (implemented as methods)\n",
    "\n",
    "### Production-Ready Features:\n",
    "\n",
    "- Complete model serialization\n",
    "- Inference functions\n",
    "- Proper preprocessing pipeline\n",
    "- Model configuration storage\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Experiment with different backbones** (VGG19, ResNet, EfficientNet)\n",
    "2. **Implement ensemble methods** combining multiple models\n",
    "3. **Add model interpretability** (Grad-CAM, attention maps)\n",
    "4. **Optimize for deployment** (model quantization, ONNX export)\n",
    "\n",
    "This implementation provides a solid foundation for visual emotion recognition using modern transfer learning techniques!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
