{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete API for Visual Emotion Recognition\n",
        "\n",
        "This notebook provides a complete API implementation for serving visual emotion recognition models.\n",
        "\n",
        "## Components Included:\n",
        "1. **Model Inference** - Load and run models for predictions\n",
        "2. **Image Processing** - Handle various image formats and preprocessing\n",
        "3. **Batch Processing** - Process multiple images efficiently\n",
        "4. **REST API Server** - Simple web server for model serving\n",
        "5. **Utilities** - Helper functions for deployment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import json\n",
        "import io\n",
        "import base64\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Model Inference Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EmotionPredictor:\n",
        "    \"\"\"\n",
        "    Complete emotion prediction class with model loading and inference.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model_path=None, model=None, transform=None, label_map=None, device='cpu'):\n",
        "        \"\"\"\n",
        "        Initialize the emotion predictor.\n",
        "        \n",
        "        Args:\n",
        "            model_path (str): Path to saved model file\n",
        "            model: Pre-loaded PyTorch model\n",
        "            transform: Image preprocessing transform\n",
        "            label_map (dict): Mapping from class indices to names\n",
        "            device (str): Device to use\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        \n",
        "        if model_path:\n",
        "            self.load_model(model_path)\n",
        "        elif model is not None:\n",
        "            self.model = model.to(device)\n",
        "            self.model.eval()\n",
        "            self.transform = transform\n",
        "            self.label_map = label_map or {}\n",
        "        else:\n",
        "            raise ValueError(\"Either model_path or model must be provided\")\n",
        "        \n",
        "        # Create inverse mapping\n",
        "        self.idx_to_label = {v: k for k, v in self.label_map.items()}\n",
        "        \n",
        "        print(f\"EmotionPredictor initialized with {len(self.label_map)} classes\")\n",
        "        print(f\"Classes: {list(self.label_map.keys())}\")\n",
        "    \n",
        "    def load_model(self, model_path):\n",
        "        \"\"\"\n",
        "        Load model from saved file.\n",
        "        \n",
        "        Args:\n",
        "            model_path (str): Path to model file\n",
        "        \"\"\"\n",
        "        checkpoint = torch.load(model_path, map_location=self.device)\n",
        "        \n",
        "        # Extract model information\n",
        "        if 'label_map' in checkpoint:\n",
        "            self.label_map = checkpoint['label_map']\n",
        "        else:\n",
        "            # Default emotion mapping\n",
        "            self.label_map = {\n",
        "                'angry': 0, 'fearful': 1, 'happy': 2, 'neutral': 3, \n",
        "                'sad': 4, 'surprised': 5, 'disgusted': 6\n",
        "            }\n",
        "        \n",
        "        # Get transforms configuration\n",
        "        if 'transforms_config' in checkpoint:\n",
        "            transforms_config = checkpoint['transforms_config']\n",
        "            self.setup_transforms(transforms_config)\n",
        "        else:\n",
        "            # Default transforms\n",
        "            self.setup_default_transforms()\n",
        "        \n",
        "        print(f\"Model loaded from {model_path}\")\n",
        "    \n",
        "    def setup_transforms(self, config):\n",
        "        \"\"\"\n",
        "        Setup transforms from configuration.\n",
        "        \n",
        "        Args:\n",
        "            config (dict): Transform configuration\n",
        "        \"\"\"\n",
        "        from torchvision import transforms\n",
        "        \n",
        "        input_size = config.get('input_size', 224)\n",
        "        mean = config.get('mean', [0.485, 0.456, 0.406])\n",
        "        std = config.get('std', [0.229, 0.224, 0.225])\n",
        "        \n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std)\n",
        "        ])\n",
        "    \n",
        "    def setup_default_transforms(self):\n",
        "        \"\"\"\n",
        "        Setup default transforms.\n",
        "        \"\"\"\n",
        "        from torchvision import transforms\n",
        "        \n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "    \n",
        "    def preprocess_image(self, image):\n",
        "        \"\"\"\n",
        "        Preprocess image for model input.\n",
        "        \n",
        "        Args:\n",
        "            image: PIL Image, numpy array, or file path\n",
        "            \n",
        "        Returns:\n",
        "            torch.Tensor: Preprocessed image tensor\n",
        "        \"\"\"\n",
        "        # Handle different input types\n",
        "        if isinstance(image, str):\n",
        "            # File path\n",
        "            image = Image.open(image)\n",
        "        elif isinstance(image, np.ndarray):\n",
        "            # Numpy array\n",
        "            if image.dtype != np.uint8:\n",
        "                image = (image * 255).astype(np.uint8)\n",
        "            image = Image.fromarray(image)\n",
        "        elif not isinstance(image, Image.Image):\n",
        "            raise ValueError(f\"Unsupported image type: {type(image)}\")\n",
        "        \n",
        "        # Convert to RGB if needed\n",
        "        if image.mode != 'RGB':\n",
        "            image = image.convert('RGB')\n",
        "        \n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            image_tensor = self.transform(image)\n",
        "        else:\n",
        "            # Basic preprocessing\n",
        "            from torchvision import transforms\n",
        "            transform = transforms.Compose([\n",
        "                transforms.Resize((224, 224)),\n",
        "                transforms.ToTensor()\n",
        "            ])\n",
        "            image_tensor = transform(image)\n",
        "        \n",
        "        return image_tensor\n",
        "    \n",
        "    def predict_single(self, image, return_probs=True, top_k=None):\n",
        "        \"\"\"\n",
        "        Predict emotion for a single image.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            return_probs (bool): Whether to return probabilities\n",
        "            top_k (int): Return top-k predictions\n",
        "            \n",
        "        Returns:\n",
        "            dict: Prediction results\n",
        "        \"\"\"\n",
        "        # Preprocess image\n",
        "        image_tensor = self.preprocess_image(image)\n",
        "        image_batch = image_tensor.unsqueeze(0).to(self.device)\n",
        "        \n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(image_batch)\n",
        "            probabilities = F.softmax(outputs, dim=1)[0]\n",
        "            \n",
        "        # Get top prediction\n",
        "        top_prob, top_idx = probabilities.max(0)\n",
        "        predicted_emotion = self.idx_to_label.get(top_idx.item(), f'Class_{top_idx.item()}')\n",
        "        \n",
        "        result = {\n",
        "            'predicted_emotion': predicted_emotion,\n",
        "            'confidence': top_prob.item()\n",
        "        }\n",
        "        \n",
        "        if return_probs:\n",
        "            # Add all class probabilities\n",
        "            all_probs = {}\n",
        "            for idx, prob in enumerate(probabilities):\n",
        "                emotion_name = self.idx_to_label.get(idx, f'Class_{idx}')\n",
        "                all_probs[emotion_name] = prob.item()\n",
        "            result['probabilities'] = all_probs\n",
        "        \n",
        "        if top_k and top_k > 1:\n",
        "            # Add top-k predictions\n",
        "            top_probs, top_indices = torch.topk(probabilities, min(top_k, len(probabilities)))\n",
        "            top_predictions = []\n",
        "            for prob, idx in zip(top_probs, top_indices):\n",
        "                emotion_name = self.idx_to_label.get(idx.item(), f'Class_{idx.item()}')\n",
        "                top_predictions.append({\n",
        "                    'emotion': emotion_name,\n",
        "                    'confidence': prob.item()\n",
        "                })\n",
        "            result['top_predictions'] = top_predictions\n",
        "        \n",
        "        return result\n",
        "    \n",
        "    def predict_batch(self, images, batch_size=32, return_probs=False):\n",
        "        \"\"\"\n",
        "        Predict emotions for a batch of images.\n",
        "        \n",
        "        Args:\n",
        "            images: List of images\n",
        "            batch_size (int): Batch size for processing\n",
        "            return_probs (bool): Whether to return probabilities\n",
        "            \n",
        "        Returns:\n",
        "            list: List of prediction results\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        \n",
        "        # Process in batches\n",
        "        for i in range(0, len(images), batch_size):\n",
        "            batch_images = images[i:i + batch_size]\n",
        "            batch_tensors = []\n",
        "            \n",
        "            # Preprocess batch\n",
        "            for image in batch_images:\n",
        "                try:\n",
        "                    tensor = self.preprocess_image(image)\n",
        "                    batch_tensors.append(tensor)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing image: {e}\")\n",
        "                    # Add dummy result for failed image\n",
        "                    results.append({\n",
        "                        'predicted_emotion': 'error',\n",
        "                        'confidence': 0.0,\n",
        "                        'error': str(e)\n",
        "                    })\n",
        "                    continue\n",
        "            \n",
        "            if not batch_tensors:\n",
        "                continue\n",
        "            \n",
        "            # Stack tensors and predict\n",
        "            batch_tensor = torch.stack(batch_tensors).to(self.device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(batch_tensor)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "            \n",
        "            # Process results\n",
        "            for probs in probabilities:\n",
        "                top_prob, top_idx = probs.max(0)\n",
        "                predicted_emotion = self.idx_to_label.get(top_idx.item(), f'Class_{top_idx.item()}')\n",
        "                \n",
        "                result = {\n",
        "                    'predicted_emotion': predicted_emotion,\n",
        "                    'confidence': top_prob.item()\n",
        "                }\n",
        "                \n",
        "                if return_probs:\n",
        "                    all_probs = {}\n",
        "                    for idx, prob in enumerate(probs):\n",
        "                        emotion_name = self.idx_to_label.get(idx, f'Class_{idx}')\n",
        "                        all_probs[emotion_name] = prob.item()\n",
        "                    result['probabilities'] = all_probs\n",
        "                \n",
        "                results.append(result)\n",
        "        \n",
        "        return results\n",
        "\n",
        "\n",
        "print(\"EmotionPredictor class created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_image_from_base64(base64_str):\n",
        "    \"\"\"\n",
        "    Load image from base64 string.\n",
        "    \n",
        "    Args:\n",
        "        base64_str (str): Base64 encoded image\n",
        "        \n",
        "    Returns:\n",
        "        PIL.Image: Loaded image\n",
        "    \"\"\"\n",
        "    # Remove data URL prefix if present\n",
        "    if base64_str.startswith('data:image/'):\n",
        "        base64_str = base64_str.split(',')[1]\n",
        "    \n",
        "    # Decode base64\n",
        "    image_data = base64.b64decode(base64_str)\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "    \n",
        "    return image\n",
        "\n",
        "\n",
        "def image_to_base64(image):\n",
        "    \"\"\"\n",
        "    Convert PIL image to base64 string.\n",
        "    \n",
        "    Args:\n",
        "        image (PIL.Image): Image to convert\n",
        "        \n",
        "    Returns:\n",
        "        str: Base64 encoded image\n",
        "    \"\"\"\n",
        "    buffered = io.BytesIO()\n",
        "    image.save(buffered, format=\"PNG\")\n",
        "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
        "    return img_str\n",
        "\n",
        "\n",
        "def create_inference_config(model_path, transforms_config=None, label_map=None):\n",
        "    \"\"\"\n",
        "    Create inference configuration file.\n",
        "    \n",
        "    Args:\n",
        "        model_path (str): Path to model file\n",
        "        transforms_config (dict): Transform configuration\n",
        "        label_map (dict): Label mapping\n",
        "        \n",
        "    Returns:\n",
        "        dict: Inference configuration\n",
        "    \"\"\"\n",
        "    config = {\n",
        "        'model_path': model_path,\n",
        "        'transforms': transforms_config or {\n",
        "            'input_size': 224,\n",
        "            'mean': [0.485, 0.456, 0.406],\n",
        "            'std': [0.229, 0.224, 0.225]\n",
        "        },\n",
        "        'label_map': label_map or {\n",
        "            'angry': 0, 'fearful': 1, 'happy': 2, 'neutral': 3,\n",
        "            'sad': 4, 'surprised': 5, 'disgusted': 6\n",
        "        },\n",
        "        'device': 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    }\n",
        "    \n",
        "    return config\n",
        "\n",
        "\n",
        "def save_inference_config(config, config_path):\n",
        "    \"\"\"\n",
        "    Save inference configuration to file.\n",
        "    \n",
        "    Args:\n",
        "        config (dict): Configuration dictionary\n",
        "        config_path (str): Path to save configuration\n",
        "    \"\"\"\n",
        "    with open(config_path, 'w') as f:\n",
        "        json.dump(config, f, indent=2)\n",
        "    print(f\"Inference configuration saved to {config_path}\")\n",
        "\n",
        "\n",
        "def load_inference_config(config_path):\n",
        "    \"\"\"\n",
        "    Load inference configuration from file.\n",
        "    \n",
        "    Args:\n",
        "        config_path (str): Path to configuration file\n",
        "        \n",
        "    Returns:\n",
        "        dict: Configuration dictionary\n",
        "    \"\"\"\n",
        "    with open(config_path, 'r') as f:\n",
        "        config = json.load(f)\n",
        "    return config\n",
        "\n",
        "\n",
        "print(\"Utility functions created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Simple Flask API Server"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_flask_app(predictor):\n",
        "    \"\"\"\n",
        "    Create Flask application for emotion recognition API.\n",
        "    \n",
        "    Args:\n",
        "        predictor (EmotionPredictor): Trained emotion predictor\n",
        "        \n",
        "    Returns:\n",
        "        Flask app\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from flask import Flask, request, jsonify\n",
        "        from flask_cors import CORS\n",
        "    except ImportError:\n",
        "        print(\"Flask not available. Install with: pip install flask flask-cors\")\n",
        "        return None\n",
        "    \n",
        "    app = Flask(__name__)\n",
        "    CORS(app)  # Enable CORS for all domains\n",
        "    \n",
        "    @app.route('/health', methods=['GET'])\n",
        "    def health_check():\n",
        "        \"\"\"Health check endpoint.\"\"\"\n",
        "        return jsonify({\n",
        "            'status': 'healthy',\n",
        "            'model_classes': list(predictor.label_map.keys()),\n",
        "            'device': predictor.device\n",
        "        })\n",
        "    \n",
        "    @app.route('/predict', methods=['POST'])\n",
        "    def predict_emotion():\n",
        "        \"\"\"Predict emotion from uploaded image.\"\"\"\n",
        "        try:\n",
        "            if 'image' not in request.files:\n",
        "                return jsonify({'error': 'No image file provided'}), 400\n",
        "            \n",
        "            file = request.files['image']\n",
        "            if file.filename == '':\n",
        "                return jsonify({'error': 'No image file selected'}), 400\n",
        "            \n",
        "            # Load image\n",
        "            image = Image.open(file.stream)\n",
        "            \n",
        "            # Get prediction parameters\n",
        "            return_probs = request.form.get('return_probs', 'false').lower() == 'true'\n",
        "            top_k = request.form.get('top_k', None)\n",
        "            if top_k:\n",
        "                top_k = int(top_k)\n",
        "            \n",
        "            # Predict\n",
        "            result = predictor.predict_single(image, return_probs=return_probs, top_k=top_k)\n",
        "            \n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'result': result\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            return jsonify({\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }), 500\n",
        "    \n",
        "    @app.route('/predict_base64', methods=['POST'])\n",
        "    def predict_base64():\n",
        "        \"\"\"Predict emotion from base64 encoded image.\"\"\"\n",
        "        try:\n",
        "            data = request.get_json()\n",
        "            \n",
        "            if 'image' not in data:\n",
        "                return jsonify({'error': 'No image data provided'}), 400\n",
        "            \n",
        "            # Load image from base64\n",
        "            image = load_image_from_base64(data['image'])\n",
        "            \n",
        "            # Get prediction parameters\n",
        "            return_probs = data.get('return_probs', False)\n",
        "            top_k = data.get('top_k', None)\n",
        "            \n",
        "            # Predict\n",
        "            result = predictor.predict_single(image, return_probs=return_probs, top_k=top_k)\n",
        "            \n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'result': result\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            return jsonify({\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }), 500\n",
        "    \n",
        "    @app.route('/predict_batch', methods=['POST'])\n",
        "    def predict_batch():\n",
        "        \"\"\"Predict emotions for multiple images.\"\"\"\n",
        "        try:\n",
        "            data = request.get_json()\n",
        "            \n",
        "            if 'images' not in data:\n",
        "                return jsonify({'error': 'No images data provided'}), 400\n",
        "            \n",
        "            # Load images from base64\n",
        "            images = []\n",
        "            for img_data in data['images']:\n",
        "                image = load_image_from_base64(img_data)\n",
        "                images.append(image)\n",
        "            \n",
        "            # Get prediction parameters\n",
        "            return_probs = data.get('return_probs', False)\n",
        "            batch_size = data.get('batch_size', 32)\n",
        "            \n",
        "            # Predict batch\n",
        "            results = predictor.predict_batch(images, batch_size=batch_size, return_probs=return_probs)\n",
        "            \n",
        "            return jsonify({\n",
        "                'success': True,\n",
        "                'results': results,\n",
        "                'count': len(results)\n",
        "            })\n",
        "            \n",
        "        except Exception as e:\n",
        "            return jsonify({\n",
        "                'success': False,\n",
        "                'error': str(e)\n",
        "            }), 500\n",
        "    \n",
        "    return app\n",
        "\n",
        "\n",
        "def run_api_server(predictor, host='0.0.0.0', port=5000, debug=False):\n",
        "    \"\"\"\n",
        "    Run Flask API server.\n",
        "    \n",
        "    Args:\n",
        "        predictor (EmotionPredictor): Trained emotion predictor\n",
        "        host (str): Host address\n",
        "        port (int): Port number\n",
        "        debug (bool): Debug mode\n",
        "    \"\"\"\n",
        "    app = create_flask_app(predictor)\n",
        "    \n",
        "    if app is None:\n",
        "        print(\"Cannot create Flask app. Make sure Flask is installed.\")\n",
        "        return\n",
        "    \n",
        "    print(f\"Starting emotion recognition API server...\")\n",
        "    print(f\"Server running at http://{host}:{port}\")\n",
        "    print(f\"Endpoints:\")\n",
        "    print(f\"  GET  /health - Health check\")\n",
        "    print(f\"  POST /predict - Single image prediction (multipart/form-data)\")\n",
        "    print(f\"  POST /predict_base64 - Single image prediction (base64 JSON)\")\n",
        "    print(f\"  POST /predict_batch - Batch prediction (base64 JSON)\")\n",
        "    \n",
        "    app.run(host=host, port=port, debug=debug)\n",
        "\n",
        "\n",
        "print(\"Flask API server functions created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Example Usage and Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def demo_api_usage():\n",
        "    \"\"\"\n",
        "    Demonstrate API usage with example code.\n",
        "    \"\"\"\n",
        "    print(\"=== Emotion Recognition API Demo ===\")\n",
        "    print()\n",
        "    \n",
        "    # Example 1: Load and use predictor directly\n",
        "    print(\"1. Direct Predictor Usage:\")\n",
        "    print(\"```python\")\n",
        "    print(\"# Load trained model\")\n",
        "    print(\"predictor = EmotionPredictor(model_path='best_model.pth')\")\n",
        "    print(\"\")\n",
        "    print(\"# Predict single image\")\n",
        "    print(\"result = predictor.predict_single('path/to/image.jpg', return_probs=True)\")\n",
        "    print(\"print(f\\\"Emotion: {result['predicted_emotion']} (Confidence: {result['confidence']:.3f})\\\")\")\n",
        "    print(\"\")\n",
        "    print(\"# Predict batch of images\")\n",
        "    print(\"images = ['img1.jpg', 'img2.jpg', 'img3.jpg']\")\n",
        "    print(\"results = predictor.predict_batch(images)\")\n",
        "    print(\"for i, result in enumerate(results):\")\n",
        "    print(\"    print(f\\\"Image {i}: {result['predicted_emotion']}\\\")\")\n",
        "    print(\"```\")\n",
        "    print()\n",
        "    \n",
        "    # Example 2: API Server\n",
        "    print(\"2. API Server Usage:\")\n",
        "    print(\"```python\")\n",
        "    print(\"# Start API server\")\n",
        "    print(\"predictor = EmotionPredictor(model_path='best_model.pth')\")\n",
        "    print(\"run_api_server(predictor, host='localhost', port=5000)\")\n",
        "    print(\"```\")\n",
        "    print()\n",
        "    \n",
        "    # Example 3: API Client\n",
        "    print(\"3. API Client Examples:\")\n",
        "    print()\n",
        "    \n",
        "    print(\"Python client:\")\n",
        "    print(\"```python\")\n",
        "    print(\"import requests\")\n",
        "    print(\"import json\")\n",
        "    print(\"\")\n",
        "    print(\"# Health check\")\n",
        "    print(\"response = requests.get('http://localhost:5000/health')\")\n",
        "    print(\"print(response.json())\")\n",
        "    print(\"\")\n",
        "    print(\"# Upload image file\")\n",
        "    print(\"with open('image.jpg', 'rb') as f:\")\n",
        "    print(\"    files = {'image': f}\")\n",
        "    print(\"    data = {'return_probs': 'true'}\")\n",
        "    print(\"    response = requests.post('http://localhost:5000/predict', files=files, data=data)\")\n",
        "    print(\"    result = response.json()\")\n",
        "    print(\"    print(result['result']['predicted_emotion'])\")\n",
        "    print(\"\")\n",
        "    print(\"# Base64 image\")\n",
        "    print(\"import base64\")\n",
        "    print(\"with open('image.jpg', 'rb') as f:\")\n",
        "    print(\"    img_b64 = base64.b64encode(f.read()).decode()\")\n",
        "    print(\"\")\n",
        "    print(\"payload = {\")\n",
        "    print(\"    'image': img_b64,\")\n",
        "    print(\"    'return_probs': True\")\n",
        "    print(\"}\")\n",
        "    print(\"response = requests.post('http://localhost:5000/predict_base64', json=payload)\")\n",
        "    print(\"result = response.json()\")\n",
        "    print(\"```\")\n",
        "    print()\n",
        "    \n",
        "    print(\"cURL examples:\")\n",
        "    print(\"```bash\")\n",
        "    print(\"# Health check\")\n",
        "    print(\"curl http://localhost:5000/health\")\n",
        "    print(\"\")\n",
        "    print(\"# Upload image\")\n",
        "    print(\"curl -X POST -F \\\"image=@image.jpg\\\" -F \\\"return_probs=true\\\" http://localhost:5000/predict\")\n",
        "    print(\"```\")\n",
        "    print()\n",
        "    \n",
        "    print(\"JavaScript (fetch) example:\")\n",
        "    print(\"```javascript\")\n",
        "    print(\"// Upload image file\")\n",
        "    print(\"const formData = new FormData();\")\n",
        "    print(\"formData.append('image', imageFile);\")\n",
        "    print(\"formData.append('return_probs', 'true');\")\n",
        "    print(\"\")\n",
        "    print(\"fetch('http://localhost:5000/predict', {\")\n",
        "    print(\"    method: 'POST',\")\n",
        "    print(\"    body: formData\")\n",
        "    print(\"})\")  \n",
        "    print(\".then(response => response.json())\")\n",
        "    print(\".then(data => {\")\n",
        "    print(\"    console.log('Predicted emotion:', data.result.predicted_emotion);\")\n",
        "    print(\"    console.log('Confidence:', data.result.confidence);\")\n",
        "    print(\"});\")\n",
        "    print(\"```\")\n",
        "\n",
        "\n",
        "def create_deployment_script():\n",
        "    \"\"\"\n",
        "    Create a deployment script for the API.\n",
        "    \n",
        "    Returns:\n",
        "        str: Deployment script content\n",
        "    \"\"\"\n",
        "    script = '''#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Emotion Recognition API Deployment Script\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Import the predictor and API functions from this notebook\n",
        "# You would copy the EmotionPredictor class and API functions here\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description='Deploy Emotion Recognition API')\n",
        "    parser.add_argument('--model_path', required=True, help='Path to trained model')\n",
        "    parser.add_argument('--host', default='0.0.0.0', help='Host address')\n",
        "    parser.add_argument('--port', type=int, default=5000, help='Port number')\n",
        "    parser.add_argument('--debug', action='store_true', help='Enable debug mode')\n",
        "    \n",
        "    args = parser.parse_args()\n",
        "    \n",
        "    # Validate model path\n",
        "    if not Path(args.model_path).exists():\n",
        "        print(f\"Model file not found: {args.model_path}\")\n",
        "        return\n",
        "    \n",
        "    # Load predictor\n",
        "    print(f\"Loading model from {args.model_path}...\")\n",
        "    predictor = EmotionPredictor(model_path=args.model_path)\n",
        "    \n",
        "    # Start API server\n",
        "    run_api_server(predictor, host=args.host, port=args.port, debug=args.debug)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "'''\n",
        "    return script\n",
        "\n",
        "\n",
        "# Run demo\n",
        "demo_api_usage()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"API implementation complete!\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides a complete API implementation for visual emotion recognition:\n",
        "\n",
        "### Core Components:\n",
        "1. **EmotionPredictor**: Complete inference class with model loading and prediction\n",
        "2. **Image Processing**: Handle various image formats, base64 encoding/decoding\n",
        "3. **Batch Processing**: Efficient processing of multiple images\n",
        "4. **REST API**: Flask-based web server with multiple endpoints\n",
        "5. **Utility Functions**: Configuration management and helper functions\n",
        "\n",
        "### Key Features:\n",
        "- **Flexible Input**: Support for file paths, PIL Images, numpy arrays, base64 strings\n",
        "- **Batch Processing**: Efficient batch prediction with configurable batch sizes\n",
        "- **REST API**: Professional web API with health checks and error handling\n",
        "- **Cross-Origin Support**: CORS enabled for web applications\n",
        "- **Configuration Management**: Easy model and transform configuration\n",
        "- **Deployment Ready**: Complete deployment scripts and examples\n",
        "\n",
        "### API Endpoints:\n",
        "- `GET /health` - Health check and model information\n",
        "- `POST /predict` - Single image prediction (multipart form)\n",
        "- `POST /predict_base64` - Single image prediction (JSON base64)\n",
        "- `POST /predict_batch` - Batch image prediction (JSON base64)\n",
        "\n",
        "### Usage Examples:\n",
        "```python\n",
        "# Direct usage\n",
        "predictor = EmotionPredictor(model_path='model.pth')\n",
        "result = predictor.predict_single('image.jpg')\n",
        "\n",
        "# API server\n",
        "run_api_server(predictor, host='localhost', port=5000)\n",
        "```\n",
        "\n",
        "All functionality is self-contained within this notebook and doesn't require the src folder structure."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}