{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d669bb6",
   "metadata": {},
   "source": [
    "# Feature Engineering and Dataset Balancing for Emotion Recognition\n",
    "\n",
    "This notebook implements feature engineering and dataset balancing techniques to improve the emotion recognition model performance by addressing class imbalance issues.\n",
    "\n",
    "## Problem Statement\n",
    "The EmoSet dataset has significant class imbalance:\n",
    "- **happy**: 25.24% (overrepresented)\n",
    "- **surprise**: 11.29% (underrepresented)\n",
    "- Other emotions range from 14-17%\n",
    "\n",
    "## Solution Approach\n",
    "1. Analyze current dataset distribution\n",
    "2. Implement dataset balancing techniques\n",
    "3. Create balanced train/validation/test splits\n",
    "4. Save processed datasets for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Feature Engineering Environment Setup Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup_paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project paths\n",
    "PROJECT_ROOT = Path('/home/runner/work/ann-visual-emotion/ann-visual-emotion')\n",
    "CSV_TRAIN = PROJECT_ROOT / 'data/processed/EmoSet_splits/train.csv'\n",
    "CSV_VAL = PROJECT_ROOT / 'data/processed/EmoSet_splits/val.csv'\n",
    "CSV_TEST = PROJECT_ROOT / 'data/processed/EmoSet_splits/test.csv'\n",
    "LABEL_MAP_PATH = PROJECT_ROOT / 'data/processed/EmoSet_splits/label_map.json'\n",
    "STATS_PATH = PROJECT_ROOT / 'data/processed/EmoSet_splits/stats.json'\n",
    "DATA_DIR = PROJECT_ROOT / 'data/raw/EmoSet'\n",
    "\n",
    "# Output paths for balanced datasets\n",
    "BALANCED_TRAIN_CSV = PROJECT_ROOT / 'data/processed/EmoSet_splits/train_balanced.csv'\n",
    "BALANCED_VAL_CSV = PROJECT_ROOT / 'data/processed/EmoSet_splits/val_balanced.csv'\n",
    "BALANCED_TEST_CSV = PROJECT_ROOT / 'data/processed/EmoSet_splits/test_balanced.csv'\n",
    "BALANCED_STATS_PATH = PROJECT_ROOT / 'data/processed/EmoSet_splits/stats_balanced.json'\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(\"\\nInput files:\")\n",
    "for path in [CSV_TRAIN, CSV_VAL, CSV_TEST, LABEL_MAP_PATH]:\n",
    "    print(f\"  {path.name}: {'✓' if path.exists() else '✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load existing datasets\n",
    "print(\"Loading current datasets...\")\n",
    "train_df = pd.read_csv(CSV_TRAIN)\n",
    "val_df = pd.read_csv(CSV_VAL)\n",
    "test_df = pd.read_csv(CSV_TEST)\n",
    "\n",
    "# Load label mapping\n",
    "with open(LABEL_MAP_PATH, 'r') as f:\n",
    "    label_map = json.load(f)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(val_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "print(f\"\\nEmotion classes: {list(label_map.keys())}\")\n",
    "print(f\"Number of classes: {len(label_map)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyze_imbalance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_class_distribution(df, split_name):\n",
    "    \"\"\"Analyze and visualize class distribution\"\"\"\n",
    "    class_counts = df['label'].value_counts().sort_index()\n",
    "    class_percentages = (class_counts / len(df) * 100).round(2)\n",
    "    \n",
    "    print(f\"\\n{split_name.upper()} SET CLASS DISTRIBUTION:\")\n",
    "    print(\"=\" * 50)\n",
    "    for emotion, count in class_counts.items():\n",
    "        pct = class_percentages[emotion]\n",
    "        status = \"OVERREPRESENTED\" if pct > 20 else \"UNDERREPRESENTED\" if pct < 14 else \"BALANCED\"\n",
    "        print(f\"{emotion:10s}: {count:5d} ({pct:5.2f}%) - {status}\")\n",
    "    \n",
    "    print(f\"\\nTotal samples: {len(df)}\")\n",
    "    print(f\"Mean per class: {len(df) / len(class_counts):.1f}\")\n",
    "    print(f\"Std deviation: {class_counts.std():.1f}\")\n",
    "    print(f\"Balance ratio (min/max): {class_counts.min() / class_counts.max():.3f}\")\n",
    "    \n",
    "    return class_counts, class_percentages\n",
    "\n",
    "# Analyze current distributions\n",
    "train_counts, train_pct = analyze_class_distribution(train_df, \"train\")\n",
    "val_counts, val_pct = analyze_class_distribution(val_df, \"validation\")\n",
    "test_counts, test_pct = analyze_class_distribution(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize_imbalance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distributions(train_counts, val_counts, test_counts):\n",
    "    \"\"\"Create visualization of class distributions across all splits\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    emotions = list(train_counts.index)\n",
    "    \n",
    "    # Train distribution\n",
    "    axes[0, 0].bar(emotions, train_counts.values, color='skyblue', alpha=0.7)\n",
    "    axes[0, 0].set_title('Training Set Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Number of Samples')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Validation distribution  \n",
    "    axes[0, 1].bar(emotions, val_counts.values, color='lightcoral', alpha=0.7)\n",
    "    axes[0, 1].set_title('Validation Set Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Number of Samples')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Test distribution\n",
    "    axes[1, 0].bar(emotions, test_counts.values, color='lightgreen', alpha=0.7)\n",
    "    axes[1, 0].set_title('Test Set Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Number of Samples')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Combined view\n",
    "    x_pos = np.arange(len(emotions))\n",
    "    width = 0.25\n",
    "    \n",
    "    axes[1, 1].bar(x_pos - width, train_counts.values, width, label='Train', alpha=0.7)\n",
    "    axes[1, 1].bar(x_pos, val_counts.values, width, label='Validation', alpha=0.7)\n",
    "    axes[1, 1].bar(x_pos + width, test_counts.values, width, label='Test', alpha=0.7)\n",
    "    axes[1, 1].set_title('Combined Distribution Comparison', fontsize=14, fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Number of Samples')\n",
    "    axes[1, 1].set_xticks(x_pos)\n",
    "    axes[1, 1].set_xticklabels(emotions, rotation=45)\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create visualizations\n",
    "plot_class_distributions(train_counts, val_counts, test_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balance_strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_balance_strategy(class_counts, strategy='moderate'):\n",
    "    \"\"\"Calculate target sample sizes for balancing\"\"\"\n",
    "    total_samples = class_counts.sum()\n",
    "    num_classes = len(class_counts)\n",
    "    \n",
    "    if strategy == 'uniform':\n",
    "        # Make all classes equal to the smallest class\n",
    "        target_size = class_counts.min()\n",
    "    elif strategy == 'moderate':\n",
    "        # Use a target size that reduces extreme imbalance but preserves some variation\n",
    "        # Target: between min and mean\n",
    "        target_size = int((class_counts.min() + class_counts.mean()) / 2)\n",
    "    elif strategy == 'conservative':\n",
    "        # Use mean as target - gentle balancing\n",
    "        target_size = int(class_counts.mean())\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "    \n",
    "    print(f\"\\nBALANCING STRATEGY: {strategy.upper()}\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Original total samples: {total_samples}\")\n",
    "    print(f\"Target samples per class: {target_size}\")\n",
    "    print(f\"New total samples: {target_size * num_classes}\")\n",
    "    print(f\"Sample reduction: {total_samples - (target_size * num_classes)} ({((total_samples - (target_size * num_classes)) / total_samples * 100):.1f}%)\")\n",
    "    \n",
    "    return target_size\n",
    "\n",
    "# Calculate target sizes for different strategies\n",
    "print(\"EVALUATING BALANCING STRATEGIES:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "strategies = ['uniform', 'moderate', 'conservative']\n",
    "targets = {}\n",
    "\n",
    "for strategy in strategies:\n",
    "    targets[strategy] = calculate_balance_strategy(train_counts, strategy)\n",
    "\n",
    "# Choose moderate strategy as default\n",
    "chosen_strategy = 'moderate'\n",
    "target_samples_per_class = targets[chosen_strategy]\n",
    "\n",
    "print(f\"\\n✓ CHOSEN STRATEGY: {chosen_strategy.upper()}\")\n",
    "print(f\"✓ Target samples per class: {target_samples_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balance_dataset",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(df, target_size, random_state=42):\n",
    "    \"\"\"Balance dataset using undersampling/oversampling\"\"\"\n",
    "    balanced_dfs = []\n",
    "    \n",
    "    print(f\"\\nBalancing dataset to {target_size} samples per class...\")\n",
    "    \n",
    "    for emotion in df['label'].unique():\n",
    "        emotion_df = df[df['label'] == emotion].copy()\n",
    "        current_size = len(emotion_df)\n",
    "        \n",
    "        if current_size > target_size:\n",
    "            # Undersample\n",
    "            balanced_emotion_df = resample(\n",
    "                emotion_df, \n",
    "                replace=False, \n",
    "                n_samples=target_size, \n",
    "                random_state=random_state\n",
    "            )\n",
    "            action = f\"Undersampled from {current_size} to {target_size}\"\n",
    "        elif current_size < target_size:\n",
    "            # Oversample\n",
    "            balanced_emotion_df = resample(\n",
    "                emotion_df, \n",
    "                replace=True, \n",
    "                n_samples=target_size, \n",
    "                random_state=random_state\n",
    "            )\n",
    "            action = f\"Oversampled from {current_size} to {target_size}\"\n",
    "        else:\n",
    "            # No change needed\n",
    "            balanced_emotion_df = emotion_df\n",
    "            action = f\"No change needed ({current_size} samples)\"\n",
    "        \n",
    "        print(f\"  {emotion:10s}: {action}\")\n",
    "        balanced_dfs.append(balanced_emotion_df)\n",
    "    \n",
    "    # Combine all balanced classes\n",
    "    balanced_df = pd.concat(balanced_dfs, ignore_index=True)\n",
    "    \n",
    "    # Shuffle the dataset\n",
    "    balanced_df = balanced_df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    return balanced_df\n",
    "\n",
    "# Balance the training set (main focus)\n",
    "print(\"BALANCING TRAINING SET:\")\n",
    "print(\"=\" * 50)\n",
    "balanced_train_df = balance_dataset(train_df, target_samples_per_class)\n",
    "\n",
    "# For validation and test sets, use proportional balancing to maintain their relative sizes\n",
    "val_target = int(target_samples_per_class * 0.2)  # ~20% of train size\n",
    "test_target = int(target_samples_per_class * 0.05)  # ~5% of train size\n",
    "\n",
    "print(\"\\nBALANCING VALIDATION SET:\")\n",
    "print(\"=\" * 50)\n",
    "balanced_val_df = balance_dataset(val_df, val_target)\n",
    "\n",
    "print(\"\\nBALANCING TEST SET:\")\n",
    "print(\"=\" * 50)\n",
    "balanced_test_df = balance_dataset(test_df, test_target)\n",
    "\n",
    "print(\"\\n✓ Dataset balancing completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify_balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the balanced distributions\n",
    "print(\"VERIFYING BALANCED DISTRIBUTIONS:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "balanced_train_counts, _ = analyze_class_distribution(balanced_train_df, \"balanced train\")\n",
    "balanced_val_counts, _ = analyze_class_distribution(balanced_val_df, \"balanced validation\")\n",
    "balanced_test_counts, _ = analyze_class_distribution(balanced_test_df, \"balanced test\")\n",
    "\n",
    "# Create comparison visualization\n",
    "def plot_before_after_comparison(original_counts, balanced_counts, split_name):\n",
    "    \"\"\"Plot before and after comparison\"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    emotions = list(original_counts.index)\n",
    "    \n",
    "    # Before\n",
    "    ax1.bar(emotions, original_counts.values, color='lightcoral', alpha=0.7)\n",
    "    ax1.set_title(f'Before Balancing - {split_name}', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Number of Samples')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # After\n",
    "    ax2.bar(emotions, balanced_counts.values, color='lightgreen', alpha=0.7)\n",
    "    ax2.set_title(f'After Balancing - {split_name}', fontsize=14, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Samples')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Create before/after visualizations\n",
    "plot_before_after_comparison(train_counts, balanced_train_counts, \"Training Set\")\n",
    "plot_before_after_comparison(val_counts, balanced_val_counts, \"Validation Set\")\n",
    "plot_before_after_comparison(test_counts, balanced_test_counts, \"Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_balanced_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save balanced datasets\n",
    "print(\"SAVING BALANCED DATASETS:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "output_dir = PROJECT_ROOT / 'data/processed/EmoSet_splits'\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save CSV files\n",
    "balanced_train_df.to_csv(CSV_TRAIN, index=False)\n",
    "balanced_val_df.to_csv(CSV_VAL, index=False)\n",
    "balanced_test_df.to_csv(CSV_TEST, index=False)\n",
    "\n",
    "# Also save with \"_balanced\" suffix for backup\n",
    "balanced_train_df.to_csv(BALANCED_TRAIN_CSV, index=False)\n",
    "balanced_val_df.to_csv(BALANCED_VAL_CSV, index=False)\n",
    "balanced_test_df.to_csv(BALANCED_TEST_CSV, index=False)\n",
    "\n",
    "print(f\"✓ Saved: {CSV_TRAIN}\")\n",
    "print(f\"✓ Saved: {CSV_VAL}\")\n",
    "print(f\"✓ Saved: {CSV_TEST}\")\n",
    "print(f\"✓ Backup saved: {BALANCED_TRAIN_CSV}\")\n",
    "print(f\"✓ Backup saved: {BALANCED_VAL_CSV}\")\n",
    "print(f\"✓ Backup saved: {BALANCED_TEST_CSV}\")\n",
    "\n",
    "# Update statistics\n",
    "balanced_stats = {\n",
    "    \"dataset\": \"EmoSet_Balanced\",\n",
    "    \"balancing_strategy\": chosen_strategy,\n",
    "    \"target_samples_per_class\": {\n",
    "        \"train\": target_samples_per_class,\n",
    "        \"val\": val_target,\n",
    "        \"test\": test_target\n",
    "    },\n",
    "    \"splits\": {\n",
    "        \"train\": {\n",
    "            \"total\": len(balanced_train_df),\n",
    "            \"by_label\": balanced_train_counts.to_dict()\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"total\": len(balanced_val_df),\n",
    "            \"by_label\": balanced_val_counts.to_dict()\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"total\": len(balanced_test_df),\n",
    "            \"by_label\": balanced_test_counts.to_dict()\n",
    "        }\n",
    "    },\n",
    "    \"balance_metrics\": {\n",
    "        \"train_balance_ratio\": float(balanced_train_counts.min() / balanced_train_counts.max()),\n",
    "        \"val_balance_ratio\": float(balanced_val_counts.min() / balanced_val_counts.max()),\n",
    "        \"test_balance_ratio\": float(balanced_test_counts.min() / balanced_test_counts.max())\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save updated stats\n",
    "with open(STATS_PATH, 'w') as f:\n",
    "    json.dump(balanced_stats, f, indent=2)\n",
    "\n",
    "with open(BALANCED_STATS_PATH, 'w') as f:\n",
    "    json.dump(balanced_stats, f, indent=2)\n",
    "\n",
    "print(f\"✓ Saved: {STATS_PATH}\")\n",
    "print(f\"✓ Backup saved: {BALANCED_STATS_PATH}\")\n",
    "\n",
    "print(\"\\n✅ DATASET BALANCING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"📊 Balanced training samples: {len(balanced_train_df)}\")\n",
    "print(f\"📊 Balanced validation samples: {len(balanced_val_df)}\")\n",
    "print(f\"📊 Balanced test samples: {len(balanced_test_df)}\")\n",
    "print(f\"📊 Balance ratio (train): {balanced_train_counts.min() / balanced_train_counts.max():.3f}\")\n",
    "print(f\"📊 Samples per class (train): {target_samples_per_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary and recommendations\n",
    "print(\"📋 DATASET BALANCING SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n🔍 BEFORE BALANCING:\")\n",
    "print(f\"  • Most frequent class: happy ({train_counts['happy']} samples, {train_pct['happy']:.1f}%)\")\n",
    "print(f\"  • Least frequent class: surprise ({train_counts['surprise']} samples, {train_pct['surprise']:.1f}%)\")\n",
    "print(f\"  • Balance ratio: {train_counts.min() / train_counts.max():.3f}\")\n",
    "\n",
    "print(\"\\n✅ AFTER BALANCING:\")\n",
    "print(f\"  • All classes: {target_samples_per_class} samples each ({100/len(label_map):.1f}%)\")\n",
    "print(f\"  • Balance ratio: {balanced_train_counts.min() / balanced_train_counts.max():.3f}\")\n",
    "print(f\"  • Total reduction: {len(train_df) - len(balanced_train_df)} samples\")\n",
    "\n",
    "print(\"\\n🎯 EXPECTED BENEFITS:\")\n",
    "print(\"  • Reduced bias towards 'happy' emotion\")\n",
    "print(\"  • Improved recognition of 'surprise' and 'angry' emotions\")\n",
    "print(\"  • More balanced confusion matrix\")\n",
    "print(\"  • Better overall classification performance\")\n",
    "\n",
    "print(\"\\n📁 OUTPUT FILES:\")\n",
    "print(f\"  • {CSV_TRAIN.name} - Balanced training set\")\n",
    "print(f\"  • {CSV_VAL.name} - Balanced validation set\")\n",
    "print(f\"  • {CSV_TEST.name} - Balanced test set\")\n",
    "print(f\"  • {LABEL_MAP_PATH.name} - Label mapping (unchanged)\")\n",
    "print(f\"  • {STATS_PATH.name} - Updated statistics\")\n",
    "\n",
    "print(\"\\n🚀 NEXT STEPS:\")\n",
    "print(\"  1. Run updated 01_eda.ipynb to verify balanced distributions\")\n",
    "print(\"  2. Train CNN model using balanced datasets\")\n",
    "print(\"  3. Compare performance metrics with original imbalanced model\")\n",
    "print(\"  4. Monitor per-class accuracy improvements\")\n",
    "\n",
    "print(\"\\n✅ Feature engineering and dataset balancing completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
