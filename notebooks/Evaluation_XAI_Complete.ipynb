{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Evaluation and XAI for Visual Emotion Recognition\n",
        "\n",
        "This notebook contains comprehensive evaluation and explainable AI functionality for visual emotion recognition.\n",
        "\n",
        "## Components Included:\n",
        "1. **Model Evaluation** - Comprehensive metrics and analysis\n",
        "2. **GradCAM** - Gradient-based visual explanations\n",
        "3. **LIME** - Local interpretable model-agnostic explanations\n",
        "4. **SHAP** - SHapley Additive exPlanations\n",
        "5. **Visualization Tools** - Various plotting and analysis functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. GradCAM Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GradCAM:\n",
        "    \"\"\"\n",
        "    Gradient-weighted Class Activation Mapping (GradCAM) for visual explanations.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, model, target_layer_name):\n",
        "        \"\"\"\n",
        "        Initialize GradCAM.\n",
        "        \n",
        "        Args:\n",
        "            model: PyTorch model\n",
        "            target_layer_name (str): Name of target layer for gradients\n",
        "        \"\"\"\n",
        "        self.model = model\n",
        "        self.target_layer_name = target_layer_name\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "        \n",
        "        # Register hooks\n",
        "        self._register_hooks()\n",
        "    \n",
        "    def _register_hooks(self):\n",
        "        \"\"\"Register forward and backward hooks.\"\"\"\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations = output.detach()\n",
        "        \n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients = grad_output[0].detach()\n",
        "        \n",
        "        # Find target layer\n",
        "        target_layer = None\n",
        "        for name, module in self.model.named_modules():\n",
        "            if name == self.target_layer_name:\n",
        "                target_layer = module\n",
        "                break\n",
        "        \n",
        "        if target_layer is None:\n",
        "            raise ValueError(f\"Layer '{self.target_layer_name}' not found in model\")\n",
        "        \n",
        "        # Register hooks\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "    \n",
        "    def generate_cam(self, input_tensor, class_idx=None):\n",
        "        \"\"\"\n",
        "        Generate GradCAM heatmap.\n",
        "        \n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): Input tensor\n",
        "            class_idx (int): Class index for explanation (None for predicted class)\n",
        "            \n",
        "        Returns:\n",
        "            np.array: GradCAM heatmap\n",
        "        \"\"\"\n",
        "        self.model.eval()\n",
        "        \n",
        "        # Forward pass\n",
        "        output = self.model(input_tensor)\n",
        "        \n",
        "        # Get class index\n",
        "        if class_idx is None:\n",
        "            class_idx = output.argmax(dim=1).item()\n",
        "        \n",
        "        # Backward pass for target class\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[0, class_idx]\n",
        "        class_score.backward()\n",
        "        \n",
        "        # Generate CAM\n",
        "        gradients = self.gradients[0]  # Remove batch dimension\n",
        "        activations = self.activations[0]  # Remove batch dimension\n",
        "        \n",
        "        # Pool gradients over spatial dimensions\n",
        "        weights = torch.mean(gradients, dim=(1, 2))\n",
        "        \n",
        "        # Weighted combination of activation maps\n",
        "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32)\n",
        "        for i, w in enumerate(weights):\n",
        "            cam += w * activations[i]\n",
        "        \n",
        "        # ReLU to keep only positive influences\n",
        "        cam = F.relu(cam)\n",
        "        \n",
        "        # Normalize\n",
        "        if cam.max() > 0:\n",
        "            cam = cam / cam.max()\n",
        "        \n",
        "        return cam.cpu().numpy()\n",
        "    \n",
        "    def visualize_cam(self, input_tensor, original_image, class_idx=None, \n",
        "                     alpha=0.4, colormap=cv2.COLORMAP_JET):\n",
        "        \"\"\"\n",
        "        Visualize GradCAM overlay on original image.\n",
        "        \n",
        "        Args:\n",
        "            input_tensor (torch.Tensor): Input tensor\n",
        "            original_image (PIL.Image or np.array): Original image\n",
        "            class_idx (int): Class index\n",
        "            alpha (float): Overlay transparency\n",
        "            colormap: OpenCV colormap\n",
        "            \n",
        "        Returns:\n",
        "            np.array: Visualization image\n",
        "        \"\"\"\n",
        "        # Generate CAM\n",
        "        cam = self.generate_cam(input_tensor, class_idx)\n",
        "        \n",
        "        # Convert original image to numpy if needed\n",
        "        if isinstance(original_image, Image.Image):\n",
        "            original_image = np.array(original_image)\n",
        "        \n",
        "        # Resize CAM to match image size\n",
        "        height, width = original_image.shape[:2]\n",
        "        cam_resized = cv2.resize(cam, (width, height))\n",
        "        \n",
        "        # Apply colormap\n",
        "        heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), colormap)\n",
        "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        # Ensure original image is RGB\n",
        "        if len(original_image.shape) == 2:  # Grayscale\n",
        "            original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2RGB)\n",
        "        \n",
        "        # Overlay heatmap on original image\n",
        "        overlay = alpha * heatmap + (1 - alpha) * original_image\n",
        "        \n",
        "        return overlay.astype(np.uint8)\n",
        "\n",
        "\n",
        "def get_gradcam_layer_name(model):\n",
        "    \"\"\"\n",
        "    Automatically detect the best layer for GradCAM based on model architecture.\n",
        "    \n",
        "    Args:\n",
        "        model: PyTorch model\n",
        "        \n",
        "    Returns:\n",
        "        str: Layer name for GradCAM\n",
        "    \"\"\"\n",
        "    model_name = model.__class__.__name__.lower()\n",
        "    \n",
        "    if 'vgg' in model_name:\n",
        "        return 'features.30'  # Last conv layer in VGG\n",
        "    elif 'resnet' in model_name or 'improved' in model_name:\n",
        "        return 'backbone.layer4'  # Last residual block\n",
        "    elif 'baseline' in model_name:\n",
        "        return 'features.12'  # Last conv layer in baseline\n",
        "    else:\n",
        "        # Try to find the last convolutional layer\n",
        "        conv_layers = []\n",
        "        for name, module in model.named_modules():\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                conv_layers.append(name)\n",
        "        \n",
        "        if conv_layers:\n",
        "            return conv_layers[-1]\n",
        "        else:\n",
        "            raise ValueError(\"Could not find suitable layer for GradCAM\")\n",
        "\n",
        "\n",
        "print(\"GradCAM implementation ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. LIME Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from lime import lime_image\n",
        "    from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
        "    LIME_AVAILABLE = True\n",
        "    print(\"LIME available for explanations\")\n",
        "except ImportError:\n",
        "    LIME_AVAILABLE = False\n",
        "    print(\"LIME not available. Install with: pip install lime\")\n",
        "\n",
        "\n",
        "if LIME_AVAILABLE:\n",
        "    class LIMEExplainer:\n",
        "        \"\"\"\n",
        "        LIME (Local Interpretable Model-agnostic Explanations) for image classification.\n",
        "        \"\"\"\n",
        "        \n",
        "        def __init__(self, model, transform, label_map=None, device='cpu'):\n",
        "            \"\"\"\n",
        "            Initialize LIME explainer.\n",
        "            \n",
        "            Args:\n",
        "                model: PyTorch model\n",
        "                transform: Image preprocessing transform\n",
        "                label_map (dict): Mapping from class names to indices\n",
        "                device (str): Device to use\n",
        "            \"\"\"\n",
        "            self.model = model\n",
        "            self.transform = transform\n",
        "            self.label_map = label_map or {}\n",
        "            self.device = device\n",
        "            \n",
        "            # Create LIME explainer\n",
        "            self.explainer = lime_image.LimeImageExplainer()\n",
        "        \n",
        "        def predict_fn(self, images):\n",
        "            \"\"\"\n",
        "            Prediction function for LIME.\n",
        "            \n",
        "            Args:\n",
        "                images (np.array): Batch of images\n",
        "                \n",
        "            Returns:\n",
        "                np.array: Prediction probabilities\n",
        "            \"\"\"\n",
        "            self.model.eval()\n",
        "            predictions = []\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                for image in images:\n",
        "                    # Convert to PIL Image\n",
        "                    if image.dtype != np.uint8:\n",
        "                        image = (image * 255).astype(np.uint8)\n",
        "                    \n",
        "                    pil_image = Image.fromarray(image)\n",
        "                    \n",
        "                    # Apply transforms\n",
        "                    input_tensor = self.transform(pil_image).unsqueeze(0).to(self.device)\n",
        "                    \n",
        "                    # Get prediction\n",
        "                    output = self.model(input_tensor)\n",
        "                    probs = F.softmax(output, dim=1)[0].cpu().numpy()\n",
        "                    predictions.append(probs)\n",
        "            \n",
        "            return np.array(predictions)\n",
        "        \n",
        "        def explain_image(self, image, top_labels=None, num_features=5, \n",
        "                         num_samples=1000, segmentation_fn=None):\n",
        "            \"\"\"\n",
        "            Explain image prediction using LIME.\n",
        "            \n",
        "            Args:\n",
        "                image (PIL.Image or np.array): Image to explain\n",
        "                top_labels (list): Labels to explain (None for top predictions)\n",
        "                num_features (int): Number of features to include in explanation\n",
        "                num_samples (int): Number of samples for LIME\n",
        "                segmentation_fn: Segmentation function\n",
        "                \n",
        "            Returns:\n",
        "                LIME explanation object\n",
        "            \"\"\"\n",
        "            # Convert image to numpy array\n",
        "            if isinstance(image, Image.Image):\n",
        "                image_array = np.array(image)\n",
        "            else:\n",
        "                image_array = image\n",
        "            \n",
        "            # Ensure RGB format\n",
        "            if len(image_array.shape) == 2:  # Grayscale\n",
        "                image_array = np.stack([image_array] * 3, axis=-1)\n",
        "            \n",
        "            # Get segmentation function\n",
        "            if segmentation_fn is None:\n",
        "                segmentation_fn = SegmentationAlgorithm('quickshift', \n",
        "                                                       kernel_size=4, \n",
        "                                                       max_dist=200, \n",
        "                                                       ratio=0.2)\n",
        "            \n",
        "            # Generate explanation\n",
        "            explanation = self.explainer.explain_instance(\n",
        "                image_array,\n",
        "                self.predict_fn,\n",
        "                top_labels=top_labels,\n",
        "                hide_color=0,\n",
        "                num_samples=num_samples,\n",
        "                segmentation_fn=segmentation_fn\n",
        "            )\n",
        "            \n",
        "            return explanation\n",
        "        \n",
        "        def visualize_explanation(self, explanation, label_idx, positive_only=True, \n",
        "                                hide_rest=False, num_features=5):\n",
        "            \"\"\"\n",
        "            Visualize LIME explanation.\n",
        "            \n",
        "            Args:\n",
        "                explanation: LIME explanation object\n",
        "                label_idx (int): Label index to visualize\n",
        "                positive_only (bool): Show only positive features\n",
        "                hide_rest (bool): Hide non-relevant regions\n",
        "                num_features (int): Number of features to show\n",
        "                \n",
        "            Returns:\n",
        "                tuple: (explanation_image, mask)\n",
        "            \"\"\"\n",
        "            image, mask = explanation.get_image_and_mask(\n",
        "                label_idx, \n",
        "                positive_only=positive_only,\n",
        "                num_features=num_features,\n",
        "                hide_rest=hide_rest\n",
        "            )\n",
        "            \n",
        "            return image, mask\n",
        "    \n",
        "    print(\"LIME implementation ready!\")\n",
        "\n",
        "else:\n",
        "    class LIMEExplainer:\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            raise ImportError(\"LIME not available. Install with: pip install lime\")\n",
        "    \n",
        "    print(\"LIME placeholder created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. SHAP Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "    print(\"SHAP available for explanations\")\n",
        "except ImportError:\n",
        "    SHAP_AVAILABLE = False\n",
        "    print(\"SHAP not available. Install with: pip install shap\")\n",
        "\n",
        "\n",
        "if SHAP_AVAILABLE:\n",
        "    class SHAPExplainer:\n",
        "        \"\"\"\n",
        "        SHAP (SHapley Additive exPlanations) for image classification.\n",
        "        \"\"\"\n",
        "        \n",
        "        def __init__(self, model, background_data, device='cpu'):\n",
        "            \"\"\"\n",
        "            Initialize SHAP explainer.\n",
        "            \n",
        "            Args:\n",
        "                model: PyTorch model\n",
        "                background_data (torch.Tensor): Background dataset for SHAP\n",
        "                device (str): Device to use\n",
        "            \"\"\"\n",
        "            self.model = model\n",
        "            self.device = device\n",
        "            \n",
        "            # Create prediction function\n",
        "            def predict_fn(x):\n",
        "                self.model.eval()\n",
        "                with torch.no_grad():\n",
        "                    x_tensor = torch.from_numpy(x).float().to(self.device)\n",
        "                    outputs = self.model(x_tensor)\n",
        "                    return F.softmax(outputs, dim=1).cpu().numpy()\n",
        "            \n",
        "            # Create SHAP explainer\n",
        "            self.explainer = shap.DeepExplainer(predict_fn, background_data.to(device))\n",
        "        \n",
        "        def explain_image(self, image_tensor, class_idx=None):\n",
        "            \"\"\"\n",
        "            Explain image prediction using SHAP.\n",
        "            \n",
        "            Args:\n",
        "                image_tensor (torch.Tensor): Image tensor to explain\n",
        "                class_idx (int): Class index to explain\n",
        "                \n",
        "            Returns:\n",
        "                np.array: SHAP values\n",
        "            \"\"\"\n",
        "            # Get SHAP values\n",
        "            shap_values = self.explainer.shap_values(image_tensor.to(self.device))\n",
        "            \n",
        "            # Return values for specific class or all classes\n",
        "            if class_idx is not None:\n",
        "                return shap_values[class_idx]\n",
        "            else:\n",
        "                return shap_values\n",
        "        \n",
        "        def visualize_explanation(self, image_tensor, shap_values, class_names=None):\n",
        "            \"\"\"\n",
        "            Visualize SHAP explanation.\n",
        "            \n",
        "            Args:\n",
        "                image_tensor (torch.Tensor): Original image tensor\n",
        "                shap_values: SHAP values\n",
        "                class_names (list): Class names for labeling\n",
        "            \"\"\"\n",
        "            # Convert tensor to numpy for visualization\n",
        "            image_np = image_tensor.cpu().numpy()\n",
        "            \n",
        "            # SHAP image plot\n",
        "            shap.image_plot(\n",
        "                shap_values,\n",
        "                image_np,\n",
        "                labels=class_names,\n",
        "                show=True\n",
        "            )\n",
        "    \n",
        "    print(\"SHAP implementation ready!\")\n",
        "\n",
        "else:\n",
        "    class SHAPExplainer:\n",
        "        def __init__(self, *args, **kwargs):\n",
        "            raise ImportError(\"SHAP not available. Install with: pip install shap\")\n",
        "    \n",
        "    print(\"SHAP placeholder created.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Comprehensive Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comprehensive_model_analysis(model, test_loader, device, label_map=None, \n",
        "                                save_results=True, results_dir='results'):\n",
        "    \"\"\"\n",
        "    Perform comprehensive model analysis and evaluation.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        test_loader: Test data loader\n",
        "        device: Device to use\n",
        "        label_map (dict): Label mapping\n",
        "        save_results (bool): Whether to save results\n",
        "        results_dir (str): Directory to save results\n",
        "        \n",
        "    Returns:\n",
        "        dict: Comprehensive analysis results\n",
        "    \"\"\"\n",
        "    import os\n",
        "    from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "    from sklearn.preprocessing import label_binarize\n",
        "    \n",
        "    print(\"Starting comprehensive model analysis...\")\n",
        "    \n",
        "    # Create results directory\n",
        "    if save_results:\n",
        "        os.makedirs(results_dir, exist_ok=True)\n",
        "    \n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_probabilities = []\n",
        "    prediction_confidence = []\n",
        "    \n",
        "    # Collect predictions\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            \n",
        "            output = model(data)\n",
        "            probabilities = F.softmax(output, dim=1)\n",
        "            predictions = output.argmax(dim=1)\n",
        "            \n",
        "            # Calculate confidence (max probability)\n",
        "            confidence = probabilities.max(dim=1)[0]\n",
        "            \n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            all_probabilities.extend(probabilities.cpu().numpy())\n",
        "            prediction_confidence.extend(confidence.cpu().numpy())\n",
        "            \n",
        "            if batch_idx % 50 == 0:\n",
        "                print(f\"Processed {batch_idx+1}/{len(test_loader)} batches\")\n",
        "    \n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    prediction_confidence = np.array(prediction_confidence)\n",
        "    \n",
        "    # Basic metrics\n",
        "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "    \n",
        "    accuracy = accuracy_score(all_targets, all_predictions)\n",
        "    f1_macro = f1_score(all_targets, all_predictions, average='macro')\n",
        "    f1_weighted = f1_score(all_targets, all_predictions, average='weighted')\n",
        "    precision_macro = precision_score(all_targets, all_predictions, average='macro', zero_division=0)\n",
        "    recall_macro = recall_score(all_targets, all_predictions, average='macro', zero_division=0)\n",
        "    \n",
        "    # Class names\n",
        "    if label_map:\n",
        "        class_names = [k for k, v in sorted(label_map.items(), key=lambda x: x[1])]\n",
        "    else:\n",
        "        unique_labels = sorted(list(set(all_targets)))\n",
        "        class_names = [f'Class_{i}' for i in unique_labels]\n",
        "    \n",
        "    num_classes = len(class_names)\n",
        "    \n",
        "    # Detailed classification report\n",
        "    report = classification_report(all_targets, all_predictions, \n",
        "                                 target_names=class_names, \n",
        "                                 output_dict=True, zero_division=0)\n",
        "    \n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(all_targets, all_predictions)\n",
        "    \n",
        "    # ROC curves for multi-class\n",
        "    if num_classes > 2:\n",
        "        # Binarize targets for multi-class ROC\n",
        "        y_test_bin = label_binarize(all_targets, classes=range(num_classes))\n",
        "        \n",
        "        # Compute ROC curve and AUC for each class\n",
        "        fpr = dict()\n",
        "        tpr = dict()\n",
        "        roc_auc = dict()\n",
        "        \n",
        "        for i in range(num_classes):\n",
        "            fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], all_probabilities[:, i])\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "        \n",
        "        # Compute micro-average ROC curve and AUC\n",
        "        fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test_bin.ravel(), all_probabilities.ravel())\n",
        "        roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
        "    else:\n",
        "        # Binary classification\n",
        "        fpr, tpr, _ = roc_curve(all_targets, all_probabilities[:, 1])\n",
        "        roc_auc = {0: auc(fpr, tpr)}\n",
        "    \n",
        "    # Confidence analysis\n",
        "    confidence_stats = {\n",
        "        'mean': np.mean(prediction_confidence),\n",
        "        'std': np.std(prediction_confidence),\n",
        "        'min': np.min(prediction_confidence),\n",
        "        'max': np.max(prediction_confidence),\n",
        "        'median': np.median(prediction_confidence)\n",
        "    }\n",
        "    \n",
        "    # Per-class accuracy\n",
        "    per_class_accuracy = {}\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        class_mask = np.array(all_targets) == i\n",
        "        if np.sum(class_mask) > 0:\n",
        "            class_acc = np.mean(np.array(all_predictions)[class_mask] == i)\n",
        "            per_class_accuracy[class_name] = class_acc\n",
        "        else:\n",
        "            per_class_accuracy[class_name] = 0.0\n",
        "    \n",
        "    # Compile results\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'f1_macro': f1_macro,\n",
        "        'f1_weighted': f1_weighted,\n",
        "        'precision_macro': precision_macro,\n",
        "        'recall_macro': recall_macro,\n",
        "        'classification_report': report,\n",
        "        'confusion_matrix': cm,\n",
        "        'roc_auc': roc_auc,\n",
        "        'fpr': fpr,\n",
        "        'tpr': tpr,\n",
        "        'confidence_stats': confidence_stats,\n",
        "        'per_class_accuracy': per_class_accuracy,\n",
        "        'predictions': all_predictions,\n",
        "        'targets': all_targets,\n",
        "        'probabilities': all_probabilities,\n",
        "        'confidence': prediction_confidence,\n",
        "        'class_names': class_names,\n",
        "        'num_classes': num_classes\n",
        "    }\n",
        "    \n",
        "    # Print summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"COMPREHENSIVE MODEL ANALYSIS RESULTS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Test Samples: {len(all_targets)}\")\n",
        "    print(f\"Number of Classes: {num_classes}\")\n",
        "    print(f\"Classes: {class_names}\")\n",
        "    print(f\"\\nOVERALL METRICS:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "    print(f\"  F1-Score (Macro): {f1_macro:.4f}\")\n",
        "    print(f\"  F1-Score (Weighted): {f1_weighted:.4f}\")\n",
        "    print(f\"  Precision (Macro): {precision_macro:.4f}\")\n",
        "    print(f\"  Recall (Macro): {recall_macro:.4f}\")\n",
        "    \n",
        "    print(f\"\\nCONFIDENCE ANALYSIS:\")\n",
        "    print(f\"  Mean Confidence: {confidence_stats['mean']:.4f}\")\n",
        "    print(f\"  Std Confidence: {confidence_stats['std']:.4f}\")\n",
        "    print(f\"  Min Confidence: {confidence_stats['min']:.4f}\")\n",
        "    print(f\"  Max Confidence: {confidence_stats['max']:.4f}\")\n",
        "    \n",
        "    print(f\"\\nPER-CLASS ACCURACY:\")\n",
        "    for class_name, acc in per_class_accuracy.items():\n",
        "        print(f\"  {class_name}: {acc:.4f} ({acc*100:.2f}%)\")\n",
        "    \n",
        "    if num_classes > 2:\n",
        "        print(f\"\\nROC AUC SCORES:\")\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            if i in roc_auc:\n",
        "                print(f\"  {class_name}: {roc_auc[i]:.4f}\")\n",
        "        if \"micro\" in roc_auc:\n",
        "            print(f\"  Micro-average: {roc_auc['micro']:.4f}\")\n",
        "    \n",
        "    # Save results if requested\n",
        "    if save_results:\n",
        "        import json\n",
        "        \n",
        "        # Save numerical results (excluding numpy arrays)\n",
        "        save_dict = {\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'confidence_stats': confidence_stats,\n",
        "            'per_class_accuracy': per_class_accuracy,\n",
        "            'class_names': class_names,\n",
        "            'num_classes': num_classes\n",
        "        }\n",
        "        \n",
        "        with open(os.path.join(results_dir, 'analysis_results.json'), 'w') as f:\n",
        "            json.dump(save_dict, f, indent=2)\n",
        "        \n",
        "        # Save arrays\n",
        "        np.save(os.path.join(results_dir, 'predictions.npy'), all_predictions)\n",
        "        np.save(os.path.join(results_dir, 'targets.npy'), all_targets)\n",
        "        np.save(os.path.join(results_dir, 'probabilities.npy'), all_probabilities)\n",
        "        np.save(os.path.join(results_dir, 'confidence.npy'), prediction_confidence)\n",
        "        np.save(os.path.join(results_dir, 'confusion_matrix.npy'), cm)\n",
        "        \n",
        "        print(f\"\\nResults saved to {results_dir}/\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "print(\"Comprehensive evaluation functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_comprehensive_results(results, figsize=(20, 12), save_path=None):\n",
        "    \"\"\"\n",
        "    Plot comprehensive analysis results.\n",
        "    \n",
        "    Args:\n",
        "        results (dict): Results from comprehensive_model_analysis\n",
        "        figsize (tuple): Figure size\n",
        "        save_path (str): Path to save plots\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
        "    \n",
        "    class_names = results['class_names']\n",
        "    cm = results['confusion_matrix']\n",
        "    confidence = results['confidence']\n",
        "    per_class_acc = results['per_class_accuracy']\n",
        "    \n",
        "    # 1. Confusion Matrix\n",
        "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    im1 = axes[0, 0].imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    axes[0, 0].set_title('Normalized Confusion Matrix')\n",
        "    axes[0, 0].set_xlabel('Predicted Label')\n",
        "    axes[0, 0].set_ylabel('True Label')\n",
        "    \n",
        "    # Add text annotations\n",
        "    thresh = cm_normalized.max() / 2.\n",
        "    for i in range(cm_normalized.shape[0]):\n",
        "        for j in range(cm_normalized.shape[1]):\n",
        "            axes[0, 0].text(j, i, f'{cm_normalized[i, j]:.2f}',\n",
        "                           ha=\"center\", va=\"center\",\n",
        "                           color=\"white\" if cm_normalized[i, j] > thresh else \"black\")\n",
        "    \n",
        "    axes[0, 0].set_xticks(range(len(class_names)))\n",
        "    axes[0, 0].set_yticks(range(len(class_names)))\n",
        "    axes[0, 0].set_xticklabels(class_names, rotation=45)\n",
        "    axes[0, 0].set_yticklabels(class_names)\n",
        "    \n",
        "    # 2. Per-class Accuracy\n",
        "    class_accs = [per_class_acc[name] for name in class_names]\n",
        "    bars = axes[0, 1].bar(class_names, class_accs, color='skyblue', alpha=0.7)\n",
        "    axes[0, 1].set_title('Per-Class Accuracy')\n",
        "    axes[0, 1].set_xlabel('Class')\n",
        "    axes[0, 1].set_ylabel('Accuracy')\n",
        "    axes[0, 1].set_ylim(0, 1)\n",
        "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, acc in zip(bars, class_accs):\n",
        "        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                       f'{acc:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "    \n",
        "    # 3. Confidence Distribution\n",
        "    axes[0, 2].hist(confidence, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
        "    axes[0, 2].axvline(confidence.mean(), color='red', linestyle='--', \n",
        "                      label=f'Mean: {confidence.mean():.3f}')\n",
        "    axes[0, 2].set_title('Prediction Confidence Distribution')\n",
        "    axes[0, 2].set_xlabel('Confidence Score')\n",
        "    axes[0, 2].set_ylabel('Frequency')\n",
        "    axes[0, 2].legend()\n",
        "    \n",
        "    # 4. ROC Curves (if available)\n",
        "    if 'fpr' in results and 'tpr' in results:\n",
        "        fpr = results['fpr']\n",
        "        tpr = results['tpr']\n",
        "        roc_auc = results['roc_auc']\n",
        "        \n",
        "        if results['num_classes'] > 2:\n",
        "            # Multi-class ROC\n",
        "            for i, class_name in enumerate(class_names):\n",
        "                if i in fpr and i in tpr:\n",
        "                    axes[1, 0].plot(fpr[i], tpr[i], \n",
        "                                   label=f'{class_name} (AUC = {roc_auc[i]:.3f})')\n",
        "            \n",
        "            if 'micro' in fpr:\n",
        "                axes[1, 0].plot(fpr['micro'], tpr['micro'], 'k--',\n",
        "                               label=f'Micro-avg (AUC = {roc_auc[\"micro\"]:.3f})')\n",
        "        else:\n",
        "            # Binary ROC\n",
        "            axes[1, 0].plot(fpr, tpr, label=f'ROC (AUC = {roc_auc[0]:.3f})')\n",
        "        \n",
        "        axes[1, 0].plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
        "        axes[1, 0].set_title('ROC Curves')\n",
        "        axes[1, 0].set_xlabel('False Positive Rate')\n",
        "        axes[1, 0].set_ylabel('True Positive Rate')\n",
        "        axes[1, 0].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    else:\n",
        "        axes[1, 0].text(0.5, 0.5, 'ROC data not available', \n",
        "                       ha='center', va='center', transform=axes[1, 0].transAxes)\n",
        "        axes[1, 0].set_title('ROC Curves')\n",
        "    \n",
        "    # 5. Classification Report Heatmap\n",
        "    if 'classification_report' in results:\n",
        "        report = results['classification_report']\n",
        "        \n",
        "        # Extract per-class metrics\n",
        "        metrics = ['precision', 'recall', 'f1-score']\n",
        "        metric_matrix = []\n",
        "        \n",
        "        for class_name in class_names:\n",
        "            if class_name in report:\n",
        "                row = [report[class_name][metric] for metric in metrics]\n",
        "                metric_matrix.append(row)\n",
        "            else:\n",
        "                metric_matrix.append([0, 0, 0])\n",
        "        \n",
        "        metric_matrix = np.array(metric_matrix)\n",
        "        \n",
        "        im2 = axes[1, 1].imshow(metric_matrix, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)\n",
        "        axes[1, 1].set_title('Per-Class Metrics Heatmap')\n",
        "        axes[1, 1].set_xlabel('Metrics')\n",
        "        axes[1, 1].set_ylabel('Classes')\n",
        "        \n",
        "        # Add text annotations\n",
        "        for i in range(len(class_names)):\n",
        "            for j, metric in enumerate(metrics):\n",
        "                text = axes[1, 1].text(j, i, f'{metric_matrix[i, j]:.3f}',\n",
        "                                      ha=\"center\", va=\"center\", color=\"black\")\n",
        "        \n",
        "        axes[1, 1].set_xticks(range(len(metrics)))\n",
        "        axes[1, 1].set_yticks(range(len(class_names)))\n",
        "        axes[1, 1].set_xticklabels(metrics)\n",
        "        axes[1, 1].set_yticklabels(class_names)\n",
        "        \n",
        "        # Add colorbar\n",
        "        plt.colorbar(im2, ax=axes[1, 1], shrink=0.8)\n",
        "    \n",
        "    # 6. Model Performance Summary\n",
        "    axes[1, 2].axis('off')\n",
        "    summary_text = f\"\"\"MODEL PERFORMANCE SUMMARY\n",
        "    \n",
        "Overall Accuracy: {results['accuracy']:.4f}\n",
        "F1-Score (Macro): {results['f1_macro']:.4f}\n",
        "F1-Score (Weighted): {results['f1_weighted']:.4f}\n",
        "Precision (Macro): {results['precision_macro']:.4f}\n",
        "Recall (Macro): {results['recall_macro']:.4f}\n",
        "\n",
        "Confidence Stats:\n",
        "  Mean: {results['confidence_stats']['mean']:.4f}\n",
        "  Std: {results['confidence_stats']['std']:.4f}\n",
        "  Min: {results['confidence_stats']['min']:.4f}\n",
        "  Max: {results['confidence_stats']['max']:.4f}\n",
        "\n",
        "Classes: {len(class_names)}\n",
        "Test Samples: {len(results['targets'])}\n",
        "    \"\"\"\n",
        "    \n",
        "    axes[1, 2].text(0.05, 0.95, summary_text, transform=axes[1, 2].transAxes,\n",
        "                    fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
        "                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        print(f\"Plots saved to {save_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_explainability_results(model, test_loader, device, num_samples=4, \n",
        "                                    methods=['gradcam'], save_dir=None):\n",
        "    \"\"\"\n",
        "    Visualize explainability results for sample predictions.\n",
        "    \n",
        "    Args:\n",
        "        model: Trained PyTorch model\n",
        "        test_loader: Test data loader\n",
        "        device: Device to use\n",
        "        num_samples (int): Number of samples to visualize\n",
        "        methods (list): Explainability methods to use\n",
        "        save_dir (str): Directory to save visualizations\n",
        "    \"\"\"\n",
        "    # Get sample data\n",
        "    data_iter = iter(test_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    \n",
        "    # Select samples\n",
        "    indices = np.random.choice(len(images), min(num_samples, len(images)), replace=False)\n",
        "    \n",
        "    if 'gradcam' in methods:\n",
        "        # Initialize GradCAM\n",
        "        try:\n",
        "            target_layer = get_gradcam_layer_name(model)\n",
        "            gradcam = GradCAM(model, target_layer)\n",
        "            \n",
        "            fig, axes = plt.subplots(2, num_samples, figsize=(4*num_samples, 8))\n",
        "            if num_samples == 1:\n",
        "                axes = axes.reshape(2, 1)\n",
        "            \n",
        "            for i, idx in enumerate(indices):\n",
        "                image = images[idx:idx+1].to(device)\n",
        "                true_label = labels[idx].item()\n",
        "                \n",
        "                # Get prediction\n",
        "                with torch.no_grad():\n",
        "                    output = model(image)\n",
        "                    pred_label = output.argmax(dim=1).item()\n",
        "                    confidence = F.softmax(output, dim=1).max().item()\n",
        "                \n",
        "                # Original image\n",
        "                orig_img = images[idx].permute(1, 2, 0).cpu().numpy()\n",
        "                if orig_img.shape[2] == 1:  # Grayscale\n",
        "                    orig_img = orig_img.squeeze(2)\n",
        "                    axes[0, i].imshow(orig_img, cmap='gray')\n",
        "                else:  # RGB\n",
        "                    # Denormalize for visualization\n",
        "                    orig_img = np.clip(orig_img * 0.5 + 0.5, 0, 1)\n",
        "                    axes[0, i].imshow(orig_img)\n",
        "                \n",
        "                axes[0, i].set_title(f'Original\\nTrue: {true_label}, Pred: {pred_label}\\nConf: {confidence:.3f}')\n",
        "                axes[0, i].axis('off')\n",
        "                \n",
        "                # GradCAM visualization\n",
        "                cam = gradcam.generate_cam(image)\n",
        "                axes[1, i].imshow(cam, cmap='hot')\n",
        "                axes[1, i].set_title(f'GradCAM Heatmap')\n",
        "                axes[1, i].axis('off')\n",
        "            \n",
        "            plt.suptitle('GradCAM Visualizations', fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            \n",
        "            if save_dir:\n",
        "                import os\n",
        "                os.makedirs(save_dir, exist_ok=True)\n",
        "                plt.savefig(os.path.join(save_dir, 'gradcam_results.png'), \n",
        "                           dpi=300, bbox_inches='tight')\n",
        "            \n",
        "            plt.show()\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"GradCAM visualization failed: {e}\")\n",
        "    \n",
        "    print(f\"Explainability visualization completed for {len(indices)} samples\")\n",
        "\n",
        "\n",
        "print(\"Visualization functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides comprehensive evaluation and explainable AI functionality:\n",
        "\n",
        "### Core Components:\n",
        "1. **GradCAM**: Gradient-based visual explanations with automatic layer detection\n",
        "2. **LIME**: Local interpretable model-agnostic explanations (if available)\n",
        "3. **SHAP**: SHapley Additive exPlanations (if available)\n",
        "4. **Comprehensive Evaluation**: Detailed metrics, ROC curves, confidence analysis\n",
        "5. **Advanced Visualizations**: Multi-panel plots with confusion matrices, ROC curves, confidence distributions\n",
        "\n",
        "### Key Features:\n",
        "- **Automatic Layer Detection**: GradCAM automatically finds suitable layers\n",
        "- **Multi-method Explanations**: Support for multiple XAI approaches\n",
        "- **Comprehensive Metrics**: Accuracy, F1-scores, precision, recall, ROC-AUC\n",
        "- **Confidence Analysis**: Prediction confidence statistics and distributions\n",
        "- **Per-class Analysis**: Detailed per-class performance metrics\n",
        "- **Rich Visualizations**: Professional-quality plots and heatmaps\n",
        "- **Results Saving**: Automatic saving of results and visualizations\n",
        "\n",
        "### Usage Examples:\n",
        "```python\n",
        "# Comprehensive analysis\n",
        "results = comprehensive_model_analysis(model, test_loader, device, label_map)\n",
        "\n",
        "# Plot results\n",
        "plot_comprehensive_results(results, save_path='analysis_plots.png')\n",
        "\n",
        "# GradCAM explanations\n",
        "visualize_explainability_results(model, test_loader, device, \n",
        "                                methods=['gradcam'], num_samples=6)\n",
        "\n",
        "# Individual explanations\n",
        "gradcam = GradCAM(model, 'features.30')\n",
        "cam = gradcam.generate_cam(image_tensor)\n",
        "```\n",
        "\n",
        "All functionality is self-contained within this notebook and doesn't require the src folder structure."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
