{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Data Handling for Visual Emotion Recognition\n",
        "\n",
        "This notebook contains all data handling functionality for visual emotion recognition, consolidating functionality from the src/data directory.\n",
        "\n",
        "## Components Included:\n",
        "1. **EmotionDataset** - Custom PyTorch dataset for emotion recognition\n",
        "2. **Data Transformations** - Image preprocessing and augmentation\n",
        "3. **Data Loaders** - Training, validation and test data loaders\n",
        "4. **Dataset Statistics** - Computing dataset statistics and visualization\n",
        "5. **Advanced Augmentations** - Albumentations integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# PyTorch imports\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "\n",
        "# Advanced augmentation\n",
        "try:\n",
        "    import albumentations as A\n",
        "    from albumentations.pytorch import ToTensorV2\n",
        "    ALBUMENTATIONS_AVAILABLE = True\n",
        "    print(\"Albumentations available for advanced augmentations\")\n",
        "except ImportError:\n",
        "    ALBUMENTATIONS_AVAILABLE = False\n",
        "    print(\"Albumentations not available, using torchvision transforms only\")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Custom Emotion Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EmotionDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Custom dataset class for emotion recognition that supports both grayscale and RGB images.\n",
        "    \n",
        "    This dataset is designed to work with both traditional CNN models (grayscale) and \n",
        "    transfer learning models (RGB) for visual emotion recognition.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, dataframe, root_dir, transform=None, label_map=None, rgb=False):\n",
        "        \"\"\"\n",
        "        Initialize the emotion dataset.\n",
        "        \n",
        "        Args:\n",
        "            dataframe (pd.DataFrame): DataFrame containing image paths and labels\n",
        "            root_dir (str or Path): Root directory containing images\n",
        "            transform (callable, optional): Optional transform to be applied on images\n",
        "            label_map (dict, optional): Dictionary mapping emotion names to indices\n",
        "            rgb (bool): If True, convert images to RGB; if False, use grayscale\n",
        "        \"\"\"\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.root_dir = Path(root_dir)\n",
        "        self.transform = transform\n",
        "        self.label_map = label_map\n",
        "        self.rgb = rgb\n",
        "        \n",
        "        # Auto-detect column names for flexibility\n",
        "        self._detect_columns()\n",
        "        \n",
        "        # Create label map if not provided\n",
        "        if self.label_map is None:\n",
        "            self.label_map = self._create_label_map()\n",
        "        \n",
        "        # Add numeric labels if not present\n",
        "        if 'label_idx' not in self.df.columns:\n",
        "            self.df['label_idx'] = self.df[self.label_col].map(self.label_map)\n",
        "        \n",
        "        print(f\"Dataset initialized:\")\n",
        "        print(f\"- Samples: {len(self.df)}\")\n",
        "        print(f\"- Image mode: {'RGB' if rgb else 'Grayscale'}\")\n",
        "        print(f\"- Path column: '{self.path_col}'\")\n",
        "        print(f\"- Label column: '{self.label_col}'\")\n",
        "        print(f\"- Classes: {list(self.label_map.keys())}\")\n",
        "        print(f\"- Class distribution:\")\n",
        "        self._print_class_distribution()\n",
        "    \n",
        "    def _detect_columns(self):\n",
        "        \"\"\"Auto-detect image path and label columns.\"\"\"\n",
        "        # Find path/image column\n",
        "        path_candidates = [c for c in self.df.columns if any(\n",
        "            keyword in c.lower() for keyword in ['path', 'file', 'image', 'img']\n",
        "        )]\n",
        "        \n",
        "        if path_candidates:\n",
        "            self.path_col = path_candidates[0]\n",
        "        else:\n",
        "            # Fallback to first column\n",
        "            self.path_col = self.df.columns[0]\n",
        "        \n",
        "        # Find label/emotion column\n",
        "        label_candidates = [c for c in self.df.columns if any(\n",
        "            keyword in c.lower() for keyword in ['label', 'emotion', 'class', 'target']\n",
        "        )]\n",
        "        \n",
        "        if label_candidates:\n",
        "            self.label_col = label_candidates[0]\n",
        "        else:\n",
        "            # Fallback to second column if available\n",
        "            if len(self.df.columns) > 1:\n",
        "                self.label_col = self.df.columns[1]\n",
        "            else:\n",
        "                raise ValueError(\"Cannot detect label column\")\n",
        "    \n",
        "    def _create_label_map(self):\n",
        "        \"\"\"Create label mapping from unique labels in the dataset.\"\"\"\n",
        "        unique_labels = sorted(self.df[self.label_col].unique())\n",
        "        return {label: idx for idx, label in enumerate(unique_labels)}\n",
        "    \n",
        "    def _print_class_distribution(self):\n",
        "        \"\"\"Print class distribution.\"\"\"\n",
        "        for emotion, count in self.df[self.label_col].value_counts().items():\n",
        "            percentage = (count / len(self.df)) * 100\n",
        "            print(f\"  {emotion}: {count} ({percentage:.1f}%)\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples.\"\"\"\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Get a sample from the dataset.\n",
        "        \n",
        "        Args:\n",
        "            idx (int): Index of the sample\n",
        "            \n",
        "        Returns:\n",
        "            tuple: (image, label) where image is a torch.Tensor and label is an int\n",
        "        \"\"\"\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "        \n",
        "        # Get image path and label\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = self.root_dir / row[self.path_col]\n",
        "        label = row['label_idx'] if 'label_idx' in row else self.label_map[row[self.label_col]]\n",
        "        \n",
        "        # Load image\n",
        "        try:\n",
        "            image = Image.open(img_path)\n",
        "            \n",
        "            # Convert to appropriate mode\n",
        "            if self.rgb:\n",
        "                image = image.convert('RGB')\n",
        "            else:\n",
        "                image = image.convert('L')  # Grayscale\n",
        "            \n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {img_path}: {e}\")\n",
        "            # Return a default image and label\n",
        "            if self.rgb:\n",
        "                default_image = torch.zeros(3, 224, 224)\n",
        "            else:\n",
        "                default_image = torch.zeros(1, 48, 48)\n",
        "            return default_image, 0\n",
        "    \n",
        "    def get_class_weights(self):\n",
        "        \"\"\"\n",
        "        Calculate class weights for handling imbalanced datasets.\n",
        "        \n",
        "        Returns:\n",
        "            torch.Tensor: Class weights for loss function\n",
        "        \"\"\"\n",
        "        label_counts = self.df[self.label_col].value_counts()\n",
        "        total_samples = len(self.df)\n",
        "        num_classes = len(self.label_map)\n",
        "        \n",
        "        # Calculate weights\n",
        "        weights = []\n",
        "        for emotion in sorted(self.label_map.keys()):\n",
        "            count = label_counts.get(emotion, 1)\n",
        "            weight = total_samples / (num_classes * count)\n",
        "            weights.append(weight)\n",
        "        \n",
        "        return torch.FloatTensor(weights)\n",
        "    \n",
        "    def get_sample_weights(self):\n",
        "        \"\"\"\n",
        "        Get weights for each sample for WeightedRandomSampler.\n",
        "        \n",
        "        Returns:\n",
        "            torch.Tensor: Sample weights\n",
        "        \"\"\"\n",
        "        class_weights = self.get_class_weights()\n",
        "        sample_weights = []\n",
        "        \n",
        "        for idx in range(len(self.df)):\n",
        "            label_name = self.df.iloc[idx][self.label_col]\n",
        "            label_idx = self.label_map[label_name]\n",
        "            sample_weights.append(class_weights[label_idx])\n",
        "        \n",
        "        return torch.FloatTensor(sample_weights)\n",
        "    \n",
        "    def visualize_samples(self, num_samples=8, figsize=(12, 8)):\n",
        "        \"\"\"\n",
        "        Visualize random samples from the dataset.\n",
        "        \n",
        "        Args:\n",
        "            num_samples (int): Number of samples to visualize\n",
        "            figsize (tuple): Figure size\n",
        "        \"\"\"\n",
        "        indices = np.random.choice(len(self.df), size=num_samples, replace=False)\n",
        "        \n",
        "        fig, axes = plt.subplots(2, num_samples//2, figsize=figsize)\n",
        "        axes = axes.flatten()\n",
        "        \n",
        "        for i, idx in enumerate(indices):\n",
        "            image, label = self[idx]\n",
        "            \n",
        "            # Convert tensor to numpy for visualization\n",
        "            if isinstance(image, torch.Tensor):\n",
        "                if self.rgb:\n",
        "                    # RGB image\n",
        "                    image_np = image.permute(1, 2, 0).numpy()\n",
        "                    # Denormalize if needed\n",
        "                    if image_np.min() < 0:  # Likely normalized\n",
        "                        image_np = (image_np * 0.5) + 0.5  # Approximate denormalization\n",
        "                    image_np = np.clip(image_np, 0, 1)\n",
        "                else:\n",
        "                    # Grayscale image\n",
        "                    image_np = image.squeeze().numpy()\n",
        "                    if image_np.min() < 0:  # Likely normalized\n",
        "                        image_np = (image_np * 0.5) + 0.5  # Approximate denormalization\n",
        "                    image_np = np.clip(image_np, 0, 1)\n",
        "            \n",
        "            # Get emotion name from label\n",
        "            emotion_name = [k for k, v in self.label_map.items() if v == label][0]\n",
        "            \n",
        "            # Display image\n",
        "            if self.rgb:\n",
        "                axes[i].imshow(image_np)\n",
        "            else:\n",
        "                axes[i].imshow(image_np, cmap='gray')\n",
        "            \n",
        "            axes[i].set_title(f'{emotion_name} (idx: {idx})')\n",
        "            axes[i].axis('off')\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Test the dataset class\n",
        "print(\"EmotionDataset class created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_transforms(input_size=224, rgb=True, augment=True, normalize=True):\n",
        "    \"\"\"\n",
        "    Get data transforms for training and validation.\n",
        "    \n",
        "    Args:\n",
        "        input_size (int): Target image size\n",
        "        rgb (bool): Whether to use RGB (True) or grayscale (False)\n",
        "        augment (bool): Whether to apply data augmentation for training\n",
        "        normalize (bool): Whether to normalize images\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary with 'train' and 'val' transforms\n",
        "    \"\"\"\n",
        "    \n",
        "    if rgb:\n",
        "        # RGB transforms\n",
        "        if normalize:\n",
        "            # ImageNet normalization for transfer learning\n",
        "            mean = [0.485, 0.456, 0.406]\n",
        "            std = [0.229, 0.224, 0.225]\n",
        "        else:\n",
        "            mean = [0.5, 0.5, 0.5]\n",
        "            std = [0.5, 0.5, 0.5]\n",
        "        \n",
        "        if augment:\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.Resize((input_size, input_size)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=15),\n",
        "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "            ])\n",
        "        else:\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.Resize((input_size, input_size)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "            ])\n",
        "        \n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "        ])\n",
        "    \n",
        "    else:\n",
        "        # Grayscale transforms\n",
        "        if normalize:\n",
        "            # Grayscale normalization (you may need to adjust these values based on your dataset)\n",
        "            mean = [0.5]\n",
        "            std = [0.5]\n",
        "        else:\n",
        "            mean = [0.5]\n",
        "            std = [0.5]\n",
        "        \n",
        "        if augment:\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.Resize((input_size, input_size)),\n",
        "                transforms.RandomHorizontalFlip(p=0.5),\n",
        "                transforms.RandomRotation(degrees=15),\n",
        "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "            ])\n",
        "        else:\n",
        "            train_transform = transforms.Compose([\n",
        "                transforms.Resize((input_size, input_size)),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "            ])\n",
        "        \n",
        "        val_transform = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean, std=std) if normalize else transforms.Lambda(lambda x: x)\n",
        "        ])\n",
        "    \n",
        "    return {\n",
        "        'train': train_transform,\n",
        "        'val': val_transform\n",
        "    }\n",
        "\n",
        "\n",
        "def get_grayscale_normalization_stats(dataset_df, root_dir, sample_size=1000):\n",
        "    \"\"\"\n",
        "    Calculate mean and std for grayscale dataset normalization.\n",
        "    \n",
        "    Args:\n",
        "        dataset_df (pd.DataFrame): Dataset dataframe\n",
        "        root_dir (str): Root directory containing images\n",
        "        sample_size (int): Number of images to sample for statistics\n",
        "        \n",
        "    Returns:\n",
        "        tuple: (mean, std) for normalization\n",
        "    \"\"\"\n",
        "    # Sample random images\n",
        "    sample_indices = np.random.choice(len(dataset_df), min(sample_size, len(dataset_df)), replace=False)\n",
        "    \n",
        "    pixel_values = []\n",
        "    \n",
        "    for idx in sample_indices:\n",
        "        try:\n",
        "            img_path = Path(root_dir) / dataset_df.iloc[idx].iloc[0]  # Assuming first column is path\n",
        "            image = Image.open(img_path).convert('L')\n",
        "            img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
        "            pixel_values.extend(img_array.flatten())\n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    pixel_values = np.array(pixel_values)\n",
        "    mean = pixel_values.mean()\n",
        "    std = pixel_values.std()\n",
        "    \n",
        "    print(f\"Calculated normalization stats from {len(sample_indices)} images:\")\n",
        "    print(f\"Mean: {mean:.6f}\")\n",
        "    print(f\"Std: {std:.6f}\")\n",
        "    \n",
        "    return mean, std\n",
        "\n",
        "\n",
        "# Test transforms\n",
        "print(\"Testing data transforms...\")\n",
        "\n",
        "# RGB transforms for transfer learning\n",
        "rgb_transforms = get_transforms(input_size=224, rgb=True, augment=True, normalize=True)\n",
        "print(\"RGB transforms created:\")\n",
        "print(f\"- Train: {len(rgb_transforms['train'].transforms)} transforms\")\n",
        "print(f\"- Val: {len(rgb_transforms['val'].transforms)} transforms\")\n",
        "\n",
        "# Grayscale transforms for CNN baseline\n",
        "gray_transforms = get_transforms(input_size=48, rgb=False, augment=True, normalize=True)\n",
        "print(\"\\nGrayscale transforms created:\")\n",
        "print(f\"- Train: {len(gray_transforms['train'].transforms)} transforms\")\n",
        "print(f\"- Val: {len(gray_transforms['val'].transforms)} transforms\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Advanced Albumentations Transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if ALBUMENTATIONS_AVAILABLE:\n",
        "    def get_albumentations_transforms(input_size=224, rgb=True, augment=True):\n",
        "        \"\"\"\n",
        "        Get advanced augmentation transforms using Albumentations.\n",
        "        \n",
        "        Args:\n",
        "            input_size (int): Target image size\n",
        "            rgb (bool): Whether to use RGB or grayscale\n",
        "            augment (bool): Whether to apply augmentation\n",
        "            \n",
        "        Returns:\n",
        "            dict: Dictionary with 'train' and 'val' transforms\n",
        "        \"\"\"\n",
        "        \n",
        "        if augment:\n",
        "            train_transform = A.Compose([\n",
        "                A.Resize(input_size, input_size),\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.Rotate(limit=15, p=0.7),\n",
        "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
        "                A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.5) if rgb else A.NoOp(),\n",
        "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=0, p=0.5),\n",
        "                A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                A.MotionBlur(blur_limit=3, p=0.2),\n",
        "                A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.3),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406] if rgb else [0.5], \n",
        "                           std=[0.229, 0.224, 0.225] if rgb else [0.5]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        else:\n",
        "            train_transform = A.Compose([\n",
        "                A.Resize(input_size, input_size),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406] if rgb else [0.5], \n",
        "                           std=[0.229, 0.224, 0.225] if rgb else [0.5]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "        \n",
        "        val_transform = A.Compose([\n",
        "            A.Resize(input_size, input_size),\n",
        "            A.Normalize(mean=[0.485, 0.456, 0.406] if rgb else [0.5], \n",
        "                       std=[0.229, 0.224, 0.225] if rgb else [0.5]),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "        \n",
        "        return {\n",
        "            'train': train_transform,\n",
        "            'val': val_transform\n",
        "        }\n",
        "    \n",
        "    \n",
        "    class AlbumentationsDataset(EmotionDataset):\n",
        "        \"\"\"\n",
        "        Enhanced dataset class using Albumentations for better data augmentation.\n",
        "        \"\"\"\n",
        "        \n",
        "        def __init__(self, dataframe, root_dir, transform=None, label_map=None, rgb=True):\n",
        "            super().__init__(dataframe, root_dir, transform=None, label_map=label_map, rgb=rgb)\n",
        "            self.albumentations_transform = transform\n",
        "            self.force_rgb = rgb\n",
        "        \n",
        "        def __getitem__(self, idx):\n",
        "            \"\"\"Get item with Albumentations transform.\"\"\"\n",
        "            if torch.is_tensor(idx):\n",
        "                idx = idx.tolist()\n",
        "            \n",
        "            # Get image path and label\n",
        "            row = self.df.iloc[idx]\n",
        "            img_path = self.root_dir / row[self.path_col]\n",
        "            label = row['label_idx'] if 'label_idx' in row else self.label_map[row[self.label_col]]\n",
        "            \n",
        "            # Load image\n",
        "            try:\n",
        "                image = Image.open(img_path)\n",
        "                \n",
        "                # Convert to appropriate mode\n",
        "                if self.force_rgb:\n",
        "                    image = image.convert('RGB')\n",
        "                else:\n",
        "                    image = image.convert('L')  # Grayscale\n",
        "                \n",
        "                # Convert to numpy array for Albumentations\n",
        "                image_np = np.array(image)\n",
        "                \n",
        "                # Apply Albumentations transform\n",
        "                if self.albumentations_transform:\n",
        "                    transformed = self.albumentations_transform(image=image_np)\n",
        "                    image = transformed['image']\n",
        "                \n",
        "                return image, label\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "                # Return a default image and label\n",
        "                if self.force_rgb:\n",
        "                    default_image = torch.zeros(3, 224, 224)\n",
        "                else:\n",
        "                    default_image = torch.zeros(1, 48, 48)\n",
        "                return default_image, 0\n",
        "    \n",
        "    \n",
        "    print(\"Albumentations transforms and dataset created successfully!\")\n",
        "    \n",
        "    # Test albumentations transforms\n",
        "    albu_transforms = get_albumentations_transforms(input_size=224, rgb=True, augment=True)\n",
        "    print(f\"Albumentations train transform: {len(albu_transforms['train'])} operations\")\n",
        "    print(f\"Albumentations val transform: {len(albu_transforms['val'])} operations\")\n",
        "\n",
        "else:\n",
        "    print(\"Albumentations not available. Install with: pip install albumentations\")\n",
        "    AlbumentationsDataset = None\n",
        "    get_albumentations_transforms = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Data Loader Creation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_data_loaders(train_df, val_df, test_df, root_dir, \n",
        "                       batch_size=32, num_workers=4, rgb=True, input_size=224,\n",
        "                       use_weighted_sampler=False, use_albumentations=False):\n",
        "    \"\"\"\n",
        "    Create PyTorch data loaders for training, validation, and testing.\n",
        "    \n",
        "    Args:\n",
        "        train_df (pd.DataFrame): Training dataset dataframe\n",
        "        val_df (pd.DataFrame): Validation dataset dataframe\n",
        "        test_df (pd.DataFrame): Test dataset dataframe\n",
        "        root_dir (str): Root directory containing images\n",
        "        batch_size (int): Batch size for data loaders\n",
        "        num_workers (int): Number of worker processes for data loading\n",
        "        rgb (bool): Whether to use RGB or grayscale images\n",
        "        input_size (int): Input image size\n",
        "        use_weighted_sampler (bool): Whether to use weighted sampling for imbalanced classes\n",
        "        use_albumentations (bool): Whether to use Albumentations for augmentation\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary containing 'train', 'val', 'test' data loaders and 'label_map'\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get transforms\n",
        "    if use_albumentations and ALBUMENTATIONS_AVAILABLE:\n",
        "        transforms_dict = get_albumentations_transforms(input_size=input_size, rgb=rgb, augment=True)\n",
        "        dataset_class = AlbumentationsDataset\n",
        "        print(\"Using Albumentations for data augmentation\")\n",
        "    else:\n",
        "        transforms_dict = get_transforms(input_size=input_size, rgb=rgb, augment=True, normalize=True)\n",
        "        dataset_class = EmotionDataset\n",
        "        print(\"Using torchvision transforms\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = dataset_class(\n",
        "        train_df, root_dir, transform=transforms_dict['train'], rgb=rgb\n",
        "    )\n",
        "    \n",
        "    val_dataset = dataset_class(\n",
        "        val_df, root_dir, transform=transforms_dict['val'], \n",
        "        label_map=train_dataset.label_map, rgb=rgb\n",
        "    )\n",
        "    \n",
        "    test_dataset = dataset_class(\n",
        "        test_df, root_dir, transform=transforms_dict['val'], \n",
        "        label_map=train_dataset.label_map, rgb=rgb\n",
        "    )\n",
        "    \n",
        "    # Create samplers\n",
        "    train_sampler = None\n",
        "    if use_weighted_sampler:\n",
        "        sample_weights = train_dataset.get_sample_weights()\n",
        "        train_sampler = WeightedRandomSampler(\n",
        "            weights=sample_weights, \n",
        "            num_samples=len(sample_weights),\n",
        "            replacement=True\n",
        "        )\n",
        "        print(\"Using WeightedRandomSampler for balanced training\")\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, \n",
        "        batch_size=batch_size,\n",
        "        sampler=train_sampler,\n",
        "        shuffle=(train_sampler is None),  # Don't shuffle if using sampler\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True,\n",
        "        drop_last=True\n",
        "    )\n",
        "    \n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    \n",
        "    print(f\"\\nData loaders created:\")\n",
        "    print(f\"- Train: {len(train_loader)} batches, {len(train_dataset)} samples\")\n",
        "    print(f\"- Val: {len(val_loader)} batches, {len(val_dataset)} samples\")\n",
        "    print(f\"- Test: {len(test_loader)} batches, {len(test_dataset)} samples\")\n",
        "    print(f\"- Batch size: {batch_size}\")\n",
        "    print(f\"- Input size: {input_size}x{input_size}\")\n",
        "    print(f\"- Image mode: {'RGB' if rgb else 'Grayscale'}\")\n",
        "    \n",
        "    return {\n",
        "        'train': train_loader,\n",
        "        'val': val_loader,\n",
        "        'test': test_loader,\n",
        "        'label_map': train_dataset.label_map,\n",
        "        'class_weights': train_dataset.get_class_weights()\n",
        "    }\n",
        "\n",
        "\n",
        "def create_quick_loaders(csv_path, root_dir, train_ratio=0.7, val_ratio=0.15, \n",
        "                        batch_size=32, rgb=True, input_size=224):\n",
        "    \"\"\"\n",
        "    Quick function to create data loaders from a single CSV file.\n",
        "    \n",
        "    Args:\n",
        "        csv_path (str): Path to CSV file containing image paths and labels\n",
        "        root_dir (str): Root directory containing images\n",
        "        train_ratio (float): Ratio of data for training\n",
        "        val_ratio (float): Ratio of data for validation\n",
        "        batch_size (int): Batch size\n",
        "        rgb (bool): Whether to use RGB images\n",
        "        input_size (int): Input image size\n",
        "        \n",
        "    Returns:\n",
        "        dict: Dictionary with data loaders and metadata\n",
        "    \"\"\"\n",
        "    # Load data\n",
        "    df = pd.read_csv(csv_path)\n",
        "    print(f\"Loaded dataset with {len(df)} samples\")\n",
        "    \n",
        "    # Split data\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    \n",
        "    # First split: train + val vs test\n",
        "    train_val_df, test_df = train_test_split(\n",
        "        df, test_size=(1 - train_ratio - val_ratio), \n",
        "        stratify=df.iloc[:, 1] if len(df.columns) > 1 else None,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    # Second split: train vs val\n",
        "    train_df, val_df = train_test_split(\n",
        "        train_val_df, test_size=(val_ratio / (train_ratio + val_ratio)),\n",
        "        stratify=train_val_df.iloc[:, 1] if len(train_val_df.columns) > 1 else None,\n",
        "        random_state=42\n",
        "    )\n",
        "    \n",
        "    print(f\"Data split:\")\n",
        "    print(f\"- Train: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"- Val: {len(val_df)} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
        "    print(f\"- Test: {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
        "    \n",
        "    # Create data loaders\n",
        "    return create_data_loaders(\n",
        "        train_df, val_df, test_df, root_dir,\n",
        "        batch_size=batch_size, rgb=rgb, input_size=input_size\n",
        "    )\n",
        "\n",
        "\n",
        "print(\"Data loader creation functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Dataset Analysis and Visualization Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def analyze_dataset(dataset_df, label_col=None, figsize=(12, 8)):\n",
        "    \"\"\"\n",
        "    Analyze dataset distribution and statistics.\n",
        "    \n",
        "    Args:\n",
        "        dataset_df (pd.DataFrame): Dataset dataframe\n",
        "        label_col (str): Name of label column (auto-detected if None)\n",
        "        figsize (tuple): Figure size for plots\n",
        "    \"\"\"\n",
        "    if label_col is None:\n",
        "        # Auto-detect label column\n",
        "        label_candidates = [c for c in dataset_df.columns if any(\n",
        "            keyword in c.lower() for keyword in ['label', 'emotion', 'class', 'target']\n",
        "        )]\n",
        "        label_col = label_candidates[0] if label_candidates else dataset_df.columns[-1]\n",
        "    \n",
        "    print(f\"Dataset Analysis\")\n",
        "    print(f\"{'='*50}\")\n",
        "    print(f\"Total samples: {len(dataset_df)}\")\n",
        "    print(f\"Label column: '{label_col}'\")\n",
        "    \n",
        "    # Class distribution\n",
        "    class_counts = dataset_df[label_col].value_counts()\n",
        "    print(f\"\\nClass Distribution:\")\n",
        "    for emotion, count in class_counts.items():\n",
        "        percentage = (count / len(dataset_df)) * 100\n",
        "        print(f\"  {emotion}: {count} samples ({percentage:.1f}%)\")\n",
        "    \n",
        "    # Calculate class imbalance\n",
        "    max_count = class_counts.max()\n",
        "    min_count = class_counts.min()\n",
        "    imbalance_ratio = max_count / min_count\n",
        "    print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:.2f}\")\n",
        "    \n",
        "    if imbalance_ratio > 2.0:\n",
        "        print(\"⚠️  Dataset is imbalanced - consider using weighted sampling or class weights\")\n",
        "    else:\n",
        "        print(\"✅ Dataset is relatively balanced\")\n",
        "    \n",
        "    # Visualize distribution\n",
        "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
        "    \n",
        "    # Bar plot\n",
        "    class_counts.plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.7)\n",
        "    axes[0].set_title('Class Distribution')\n",
        "    axes[0].set_xlabel('Emotion')\n",
        "    axes[0].set_ylabel('Count')\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # Pie chart\n",
        "    class_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', startangle=90)\n",
        "    axes[1].set_title('Class Distribution (Percentage)')\n",
        "    axes[1].set_ylabel('')  # Remove ylabel for pie chart\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_batch(data_loader, num_samples=8, figsize=(12, 8), denormalize=True):\n",
        "    \"\"\"\n",
        "    Visualize a batch of data from a data loader.\n",
        "    \n",
        "    Args:\n",
        "        data_loader (DataLoader): PyTorch data loader\n",
        "        num_samples (int): Number of samples to visualize\n",
        "        figsize (tuple): Figure size\n",
        "        denormalize (bool): Whether to denormalize images for visualization\n",
        "    \"\"\"\n",
        "    # Get one batch\n",
        "    data_iter = iter(data_loader)\n",
        "    images, labels = next(data_iter)\n",
        "    \n",
        "    # Get label map (assuming it's stored in dataset)\n",
        "    label_map = data_loader.dataset.label_map\n",
        "    inverse_label_map = {v: k for k, v in label_map.items()}\n",
        "    \n",
        "    # Select samples to display\n",
        "    num_samples = min(num_samples, len(images))\n",
        "    indices = np.random.choice(len(images), num_samples, replace=False)\n",
        "    \n",
        "    fig, axes = plt.subplots(2, num_samples//2, figsize=figsize)\n",
        "    axes = axes.flatten() if num_samples > 1 else [axes]\n",
        "    \n",
        "    for i, idx in enumerate(indices):\n",
        "        image = images[idx]\n",
        "        label = labels[idx].item()\n",
        "        emotion_name = inverse_label_map[label]\n",
        "        \n",
        "        # Convert tensor to numpy\n",
        "        if image.shape[0] == 3:  # RGB\n",
        "            img_np = image.permute(1, 2, 0).numpy()\n",
        "            if denormalize:\n",
        "                # Approximate denormalization for ImageNet\n",
        "                img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            img_np = np.clip(img_np, 0, 1)\n",
        "            axes[i].imshow(img_np)\n",
        "        else:  # Grayscale\n",
        "            img_np = image.squeeze().numpy()\n",
        "            if denormalize:\n",
        "                img_np = img_np * 0.5 + 0.5  # Approximate denormalization\n",
        "            img_np = np.clip(img_np, 0, 1)\n",
        "            axes[i].imshow(img_np, cmap='gray')\n",
        "        \n",
        "        axes[i].set_title(f'{emotion_name}')\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.suptitle(f'Sample Batch from Data Loader')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"Batch info:\")\n",
        "    print(f\"- Batch size: {len(images)}\")\n",
        "    print(f\"- Image shape: {images[0].shape}\")\n",
        "    print(f\"- Image dtype: {images[0].dtype}\")\n",
        "    print(f\"- Labels: {labels[:num_samples].tolist()}\")\n",
        "\n",
        "\n",
        "def compute_dataset_statistics(dataset_df, root_dir, sample_size=1000, rgb=True):\n",
        "    \"\"\"\n",
        "    Compute pixel statistics for the dataset.\n",
        "    \n",
        "    Args:\n",
        "        dataset_df (pd.DataFrame): Dataset dataframe\n",
        "        root_dir (str): Root directory containing images\n",
        "        sample_size (int): Number of images to sample\n",
        "        rgb (bool): Whether images are RGB or grayscale\n",
        "        \n",
        "    Returns:\n",
        "        dict: Statistics dictionary\n",
        "    \"\"\"\n",
        "    print(f\"Computing dataset statistics from {min(sample_size, len(dataset_df))} images...\")\n",
        "    \n",
        "    # Sample images\n",
        "    sample_indices = np.random.choice(len(dataset_df), min(sample_size, len(dataset_df)), replace=False)\n",
        "    \n",
        "    pixel_values = [] if not rgb else [[], [], []]  # For RGB channels\n",
        "    image_sizes = []\n",
        "    \n",
        "    for idx in sample_indices:\n",
        "        try:\n",
        "            img_path = Path(root_dir) / dataset_df.iloc[idx].iloc[0]\n",
        "            image = Image.open(img_path)\n",
        "            \n",
        "            if rgb:\n",
        "                image = image.convert('RGB')\n",
        "                img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n",
        "                # Separate channels\n",
        "                for c in range(3):\n",
        "                    pixel_values[c].extend(img_array[:, :, c].flatten())\n",
        "            else:\n",
        "                image = image.convert('L')\n",
        "                img_array = np.array(image) / 255.0\n",
        "                pixel_values.extend(img_array.flatten())\n",
        "            \n",
        "            image_sizes.append(image.size)\n",
        "            \n",
        "        except Exception as e:\n",
        "            continue\n",
        "    \n",
        "    if rgb:\n",
        "        # RGB statistics\n",
        "        means = [np.mean(pixel_values[c]) for c in range(3)]\n",
        "        stds = [np.std(pixel_values[c]) for c in range(3)]\n",
        "        print(f\"RGB Statistics:\")\n",
        "        print(f\"  Mean: {means}\")\n",
        "        print(f\"  Std:  {stds}\")\n",
        "        stats = {'mean': means, 'std': stds, 'rgb': True}\n",
        "    else:\n",
        "        # Grayscale statistics\n",
        "        mean = np.mean(pixel_values)\n",
        "        std = np.std(pixel_values)\n",
        "        print(f\"Grayscale Statistics:\")\n",
        "        print(f\"  Mean: {mean:.6f}\")\n",
        "        print(f\"  Std:  {std:.6f}\")\n",
        "        stats = {'mean': [mean], 'std': [std], 'rgb': False}\n",
        "    \n",
        "    # Image size statistics\n",
        "    unique_sizes = list(set(image_sizes))\n",
        "    print(f\"\\nImage Size Statistics:\")\n",
        "    print(f\"  Unique sizes: {unique_sizes[:10]}{'...' if len(unique_sizes) > 10 else ''}\")\n",
        "    print(f\"  Most common size: {Counter(image_sizes).most_common(1)[0]}\")\n",
        "    \n",
        "    stats['image_sizes'] = image_sizes\n",
        "    return stats\n",
        "\n",
        "\n",
        "print(\"Dataset analysis and visualization functions ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides a complete data handling pipeline for visual emotion recognition:\n",
        "\n",
        "### Core Components:\n",
        "1. **EmotionDataset**: Flexible PyTorch dataset class supporting both RGB and grayscale images\n",
        "2. **Data Transforms**: Standard torchvision transforms with proper normalization\n",
        "3. **Advanced Augmentations**: Albumentations integration for better augmentation\n",
        "4. **Data Loaders**: Functions to create training, validation, and test data loaders\n",
        "5. **Analysis Tools**: Dataset statistics, visualization, and imbalance analysis\n",
        "\n",
        "### Key Features:\n",
        "- **Auto-detection** of column names for flexibility\n",
        "- **Class balancing** with weighted sampling\n",
        "- **Comprehensive augmentation** strategies\n",
        "- **Visualization tools** for data exploration\n",
        "- **Statistics computation** for normalization\n",
        "- **Error handling** for robust data loading\n",
        "\n",
        "All functionality is self-contained within this notebook and doesn't require the src folder structure."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}