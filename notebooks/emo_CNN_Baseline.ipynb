{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahirumanulanka/ann-visual-emotion/blob/main/notebooks/emo_CNN_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f7f7ab",
      "metadata": {
        "id": "17f7f7ab"
      },
      "source": [
        "## 1) Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "a7a2beec",
      "metadata": {
        "id": "a7a2beec"
      },
      "outputs": [],
      "source": [
        "import os, math, json, random, time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioZLkX_4w5mF",
        "outputId": "4f48af61-c223-4ae7-95ab-a6b9376d4419"
      },
      "id": "ioZLkX_4w5mF",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381e8932",
      "metadata": {
        "id": "381e8932"
      },
      "source": [
        "## 2) Config & Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "76bea1bc",
      "metadata": {
        "id": "76bea1bc"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/ann-visual-emotion/data/processed/EmoSet_splits\"\n",
        "BASE_DATA_URL = \"/content/ann-visual-emotion\"\n",
        "\n",
        "# File paths\n",
        "CSV_TRAIN = f\"{BASE_DIR}/train.csv\"\n",
        "CSV_VAL   = f\"{BASE_DIR}/val.csv\"\n",
        "CSV_TEST  = f\"{BASE_DIR}/test.csv\"\n",
        "\n",
        "# Column names in the CSVs\n",
        "COL_IMAGE = 'image'\n",
        "COL_LABEL = 'label'\n",
        "\n",
        "# Training hyperparameters\n",
        "IMG_SIZE     = 224\n",
        "BATCH_SIZE   = 32\n",
        "EPOCHS       = 20\n",
        "BASE_LR      = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LABEL_SMOOTH = 0.05\n",
        "USE_SAMPLER  = True            # balanced mini-batches\n",
        "MIXUP_ALPHA  = 0.0             # set to 0.2~0.4 to enable MixUp\n",
        "\n",
        "# Checkpoint path\n",
        "CKPT_PATH = 'best_resnet18_balanced.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3346744c",
      "metadata": {
        "id": "3346744c"
      },
      "source": [
        "## 3) Load CSVs & Quick EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "91e96d29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e96d29",
        "outputId": "346f6899-e5e1-4500-92b7-694698573ecc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 13864 Val: 1734 Test: 1734\n",
            "                                          image_path        label\n",
            "0  data/raw/EmoSet/contentment/contentment_09260.jpg  contentment\n",
            "1              data/raw/EmoSet/anger/anger_06224.jpg        anger\n",
            "2  data/raw/EmoSet/contentment/contentment_03550.jpg  contentment\n",
            "3          data/raw/EmoSet/sadness/sadness_08827.jpg      sadness\n",
            "4  data/raw/EmoSet/contentment/contentment_09558.jpg  contentment\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(CSV_TRAIN)\n",
        "val_df   = pd.read_csv(CSV_VAL)\n",
        "test_df  = pd.read_csv(CSV_TEST)\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "da44799f",
      "metadata": {
        "id": "da44799f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _auto_column(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise KeyError(f\"None of {candidates} found. Columns: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "def load_csvs(csv_train, csv_val, csv_test=None, col_image='image_path', col_label='label'):\n",
        "    tr = pd.read_csv(csv_train)\n",
        "    va = pd.read_csv(csv_val)\n",
        "    te = pd.read_csv(csv_test) if csv_test and os.path.exists(csv_test) else None\n",
        "\n",
        "    if col_image not in tr.columns:\n",
        "        col_image = _auto_column(tr, ['image_path','image','filepath','path','img_path','img'])\n",
        "    if col_label not in tr.columns:\n",
        "        col_label = _auto_column(tr, ['label','emotion','target','y'])\n",
        "\n",
        "    for df in (tr, va) + ((te,) if te is not None else ()):\n",
        "        df[col_image] = df[col_image].astype(str)\n",
        "        df[col_label] = df[col_label].astype(str)\n",
        "\n",
        "    labels = sorted(tr[col_label].unique().tolist())\n",
        "    label_to_idx = {l:i for i,l in enumerate(labels)}\n",
        "    idx_to_label = {i:l for l,i in label_to_idx.items()}\n",
        "\n",
        "    tr['y'] = tr[col_label].map(label_to_idx)\n",
        "    va['y'] = va[col_label].map(label_to_idx)\n",
        "    if te is not None:\n",
        "        before = len(te)\n",
        "        te = te[te[col_label].isin(labels)].copy()\n",
        "        if len(te) < before:\n",
        "            print(f\"[WARN] Dropped {before-len(te)} test rows with unseen labels.\")\n",
        "        te['y'] = te[col_label].map(label_to_idx)\n",
        "\n",
        "    return tr, va, te, label_to_idx, idx_to_label, col_image, col_label\n",
        "\n",
        "\n",
        "def resolve_path(p: str) -> str:\n",
        "    \"\"\"Return an absolute path. If not existing, try join with BASE_DATA_URL.\"\"\"\n",
        "    # Already absolute and exists\n",
        "    if os.path.isabs(p) and os.path.exists(p):\n",
        "        return p\n",
        "    # Try relative to BASE_DATA_URL\n",
        "    cand = os.path.join(BASE_DATA_URL, p.lstrip('/'))\n",
        "    if os.path.exists(cand):\n",
        "        return cand\n",
        "    # As last resort, return original (may be handled by PIL if path becomes valid in Colab mount)\n",
        "    return p\n",
        "\n",
        "\n",
        "class ImageCSVDataset(Dataset):\n",
        "    def __init__(self, df, img_col, y_col='y', transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_col = img_col\n",
        "        self.y_col = y_col\n",
        "        self.tfm = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = resolve_path(row[self.img_col])\n",
        "        y = int(row[self.y_col])\n",
        "        with Image.open(path) as im:\n",
        "            im = im.convert('RGB')\n",
        "        if self.tfm:\n",
        "            im = self.tfm(im)\n",
        "        return im, y\n",
        "\n",
        "\n",
        "def compute_class_weights(y_int, power=0.5):\n",
        "    counts = np.bincount(y_int)\n",
        "    counts[counts==0] = 1\n",
        "    w = (1.0 / counts) ** power\n",
        "    w = w / w.sum() * len(counts)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def make_sampler(y_int):\n",
        "    class_count = np.bincount(y_int)\n",
        "    class_count[class_count==0] = 1\n",
        "    class_weight = 1.0 / class_count\n",
        "    sample_weight = np.array([class_weight[y] for y in y_int])\n",
        "    return WeightedRandomSampler(weights=torch.from_numpy(sample_weight).double(),\n",
        "                                 num_samples=len(sample_weight),\n",
        "                                 replacement=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSVs\n",
        "train_df, val_df, test_df, label_to_idx, idx_to_label, COL_IMAGE, COL_LABEL = load_csvs(\n",
        "    CSV_TRAIN, CSV_VAL, CSV_TEST, COL_IMAGE, COL_LABEL\n",
        ")\n",
        "NUM_CLASSES = len(label_to_idx)\n",
        "print('Classes:', label_to_idx)\n",
        "\n",
        "# Transforms (ImageNet mean/std)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE + 32),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "train_ds = ImageCSVDataset(train_df, img_col=COL_IMAGE, transform=train_tfms)\n",
        "val_ds   = ImageCSVDataset(val_df,   img_col=COL_IMAGE, transform=val_tfms)\n",
        "test_ds  = ImageCSVDataset(test_df,  img_col=COL_IMAGE, transform=val_tfms) if test_df is not None else None\n",
        "\n",
        "# Sampler / Loaders\n",
        "sampler = make_sampler(train_df['y'].values) if USE_SAMPLER else None\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=(sampler is None),\n",
        "                          sampler=sampler, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True) if test_ds is not None else None\n",
        "\n",
        "# Class weights (for CE)\n",
        "class_weights = compute_class_weights(train_df['y'].values, power=0.5).to(device)\n",
        "print('Class weights:', class_weights.cpu().numpy().round(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-e8jhnnCadn",
        "outputId": "15d0f036-e369-43f5-d636-48d3ba487577"
      },
      "id": "q-e8jhnnCadn",
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {'amusement': 0, 'anger': 1, 'awe': 2, 'contentment': 3, 'disgust': 4, 'excitement': 5, 'fear': 6, 'sadness': 7}\n",
            "Class weights: [0.341 0.563 0.85  0.376 4.109 0.269 0.99  0.503]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def build_model(num_classes):\n",
        "    net = models.resnet18(weights=weights)\n",
        "    # freeze all\n",
        "    for p in net.parameters():\n",
        "        p.requires_grad = False\n",
        "    # unfreeze last block\n",
        "    for p in net.layer4.parameters():\n",
        "        p.requires_grad = True\n",
        "    in_features = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_features, num_classes)\n",
        "    return net\n",
        "\n",
        "model = build_model(NUM_CLASSES).to(device)\n",
        "\n",
        "# Optimizer / Scheduler\n",
        "opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                        lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvqUQT-6Ce3G",
        "outputId": "0c58786c-b87b-4656-aea5-409b0c3ed9b7"
      },
      "id": "wvqUQT-6Ce3G",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3403297958.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mixup(images, labels, alpha=0.2):\n",
        "    if alpha <= 0.0:\n",
        "        return images, labels, labels, 1.0, False\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(images.size(0), device=images.device)\n",
        "    mixed_x = lam * images + (1 - lam) * images[index, :]\n",
        "    y_a, y_b = labels, labels[index]\n",
        "    return mixed_x, y_a, y_b, lam, True"
      ],
      "metadata": {
        "id": "PbbtFJAjCgTH"
      },
      "id": "PbbtFJAjCgTH",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch_pass(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    all_preds, all_tgts = [], []\n",
        "    total_loss, total_n = 0.0, 0\n",
        "\n",
        "    for ims, ys in loader:\n",
        "        ims, ys = ims.to(device), ys.to(device)\n",
        "        if train:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "            ims2, y_a, y_b, lam, used_mix = mixup(ims, ys, alpha=MIXUP_ALPHA if train else 0.0)\n",
        "            logits = model(ims2)\n",
        "            if used_mix:\n",
        "                loss = lam*F.cross_entropy(logits, y_a, weight=class_weights, label_smoothing=LABEL_SMOOTH) + \\\n",
        "                       (1-lam)*F.cross_entropy(logits, y_b, weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
        "            else:\n",
        "                loss = F.cross_entropy(logits, ys, weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * ims.size(0)\n",
        "        total_n    += ims.size(0)\n",
        "        all_preds.append(logits.detach().cpu())\n",
        "        all_tgts.append(ys.detach().cpu())\n",
        "\n",
        "    if train:\n",
        "        scheduler.step()\n",
        "\n",
        "    y_true = torch.cat(all_tgts).numpy()\n",
        "    y_pred = torch.cat(all_preds).argmax(1).numpy()\n",
        "\n",
        "    # macro-F1 (simple sklearn computation)\n",
        "    from sklearn.metrics import f1_score, accuracy_score\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    return total_loss/total_n, f1, acc, y_true, y_pred"
      ],
      "metadata": {
        "id": "5P2MJj22ChDd"
      },
      "id": "5P2MJj22ChDd",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "best_f1 = 0.0\n",
        "history = []\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    tr_loss, tr_f1, tr_acc, _, _ = epoch_pass(train_loader, train=True)\n",
        "    va_loss, va_f1, va_acc, y_true, y_pred = epoch_pass(val_loader, train=False)\n",
        "    dt = time.time()-t0\n",
        "    print(f\"Epoch {epoch:02d} | train_loss {tr_loss:.4f} F1 {tr_f1:.3f} acc {tr_acc:.3f} || val_loss {va_loss:.4f} F1 {va_f1:.3f} acc {va_acc:.3f}  [{dt:.1f}s]\")\n",
        "    history.append((epoch, tr_loss, tr_f1, tr_acc, va_loss, va_f1, va_acc))\n",
        "\n",
        "    if va_f1 > best_f1:\n",
        "        best_f1 = va_f1\n",
        "        torch.save({'model': model.state_dict(),\n",
        "                    'label_to_idx': label_to_idx,\n",
        "                    'idx_to_label': idx_to_label}, CKPT_PATH)\n",
        "        print('  -> saved best checkpoint')\n",
        "\n",
        "# Optionally unfreeze more and continue training if plateau (run again with different setup)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "me9KEVipCjZr",
        "outputId": "679abf4d-82e0-4709-f816-a94c6d6c1442"
      },
      "id": "me9KEVipCjZr",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-493716025.py:13: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4294321104.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mva_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mva_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-493716025.py\u001b[0m in \u001b[0;36mepoch_pass\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1492\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}