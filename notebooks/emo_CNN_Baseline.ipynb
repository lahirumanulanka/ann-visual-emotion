{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lahirumanulanka/ann-visual-emotion/blob/main/notebooks/emo_CNN_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17f7f7ab",
      "metadata": {
        "id": "17f7f7ab"
      },
      "source": [
        "## 1) Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "a7a2beec",
      "metadata": {
        "id": "a7a2beec"
      },
      "outputs": [],
      "source": [
        "import os, math, json, random, time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms, models\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ioZLkX_4w5mF",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioZLkX_4w5mF",
        "outputId": "4f48af61-c223-4ae7-95ab-a6b9376d4419"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "381e8932",
      "metadata": {
        "id": "381e8932"
      },
      "source": [
        "## 2) Config & Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "76bea1bc",
      "metadata": {
        "id": "76bea1bc"
      },
      "outputs": [],
      "source": [
        "BASE_DIR = \"/content/ann-visual-emotion/data/processed/EmoSet_splits\"\n",
        "BASE_DATA_URL = \"/content/ann-visual-emotion\"\n",
        "\n",
        "# File paths\n",
        "CSV_TRAIN = \"../data/processed/EmoSet_splits/train.csv\"\n",
        "CSV_VAL   = \"../data/processed/EmoSet_splits/val.csv\"\n",
        "CSV_TEST  = \"../data/processed/EmoSet_splits/test.csv\"\n",
        "LABEL_MAP_JSON = \"../data/processed/EmoSet_splits/label_map.json\"\n",
        "STATS_JSON     = \"../data/processed/EmoSet_splits/stats.json\"   \n",
        "\n",
        "# Column names in the CSVs\n",
        "COL_IMAGE = 'image'\n",
        "COL_LABEL = 'label'\n",
        "\n",
        "# Training hyperparameters\n",
        "IMG_SIZE     = 224\n",
        "BATCH_SIZE   = 32\n",
        "EPOCHS       = 20\n",
        "BASE_LR      = 3e-4\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LABEL_SMOOTH = 0.05\n",
        "USE_SAMPLER  = True            # balanced mini-batches\n",
        "MIXUP_ALPHA  = 0.0             # set to 0.2~0.4 to enable MixUp\n",
        "\n",
        "# Checkpoint path\n",
        "CKPT_PATH = 'best_resnet18_balanced.pt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3346744c",
      "metadata": {
        "id": "3346744c"
      },
      "source": [
        "## 3) Load CSVs & Quick EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "91e96d29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91e96d29",
        "outputId": "346f6899-e5e1-4500-92b7-694698573ecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 28821 Val: 5653 Test: 1413\n",
            "                filepath  label  label_id  split\n",
            "0  train/angry/14147.jpg  angry         0  train\n",
            "1  train/angry/24084.jpg  angry         0  train\n",
            "2    train/angry/823.jpg  angry         0  train\n",
            "3  train/angry/19463.jpg  angry         0  train\n",
            "4  train/angry/30797.jpg  angry         0  train\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv(CSV_TRAIN)\n",
        "val_df   = pd.read_csv(CSV_VAL)\n",
        "test_df  = pd.read_csv(CSV_TEST)\n",
        "\n",
        "print(\"Train:\", len(train_df), \"Val:\", len(val_df), \"Test:\", len(test_df))\n",
        "print(train_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "da44799f",
      "metadata": {
        "id": "da44799f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def _auto_column(df, candidates):\n",
        "    for c in candidates:\n",
        "        if c in df.columns:\n",
        "            return c\n",
        "    raise KeyError(f\"None of {candidates} found. Columns: {list(df.columns)}\")\n",
        "\n",
        "\n",
        "def load_csvs(csv_train, csv_val, csv_test=None, col_image='image_path', col_label='label'):\n",
        "    tr = pd.read_csv(csv_train)\n",
        "    va = pd.read_csv(csv_val)\n",
        "    te = pd.read_csv(csv_test) if csv_test and os.path.exists(csv_test) else None\n",
        "\n",
        "    if col_image not in tr.columns:\n",
        "        col_image = _auto_column(tr, ['image_path','image','filepath','path','img_path','img'])\n",
        "    if col_label not in tr.columns:\n",
        "        col_label = _auto_column(tr, ['label','emotion','target','y'])\n",
        "\n",
        "    for df in (tr, va) + ((te,) if te is not None else ()):\n",
        "        df[col_image] = df[col_image].astype(str)\n",
        "        df[col_label] = df[col_label].astype(str)\n",
        "\n",
        "    labels = sorted(tr[col_label].unique().tolist())\n",
        "    label_to_idx = {l:i for i,l in enumerate(labels)}\n",
        "    idx_to_label = {i:l for l,i in label_to_idx.items()}\n",
        "\n",
        "    tr['y'] = tr[col_label].map(label_to_idx)\n",
        "    va['y'] = va[col_label].map(label_to_idx)\n",
        "    if te is not None:\n",
        "        before = len(te)\n",
        "        te = te[te[col_label].isin(labels)].copy()\n",
        "        if len(te) < before:\n",
        "            print(f\"[WARN] Dropped {before-len(te)} test rows with unseen labels.\")\n",
        "        te['y'] = te[col_label].map(label_to_idx)\n",
        "\n",
        "    return tr, va, te, label_to_idx, idx_to_label, col_image, col_label\n",
        "\n",
        "\n",
        "def resolve_path(p: str) -> str:\n",
        "    \"\"\"Return an absolute path. If not existing, try join with BASE_DATA_URL.\"\"\"\n",
        "    # Already absolute and exists\n",
        "    if os.path.isabs(p) and os.path.exists(p):\n",
        "        return p\n",
        "    # Try relative to BASE_DATA_URL\n",
        "    cand = os.path.join(BASE_DATA_URL, p.lstrip('/'))\n",
        "    if os.path.exists(cand):\n",
        "        return cand\n",
        "    # As last resort, return original (may be handled by PIL if path becomes valid in Colab mount)\n",
        "    return p\n",
        "\n",
        "\n",
        "class ImageCSVDataset(Dataset):\n",
        "    def __init__(self, df, img_col, y_col='y', transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.img_col = img_col\n",
        "        self.y_col = y_col\n",
        "        self.tfm = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        path = resolve_path(row[self.img_col])\n",
        "        y = int(row[self.y_col])\n",
        "        with Image.open(path) as im:\n",
        "            im = im.convert('RGB')\n",
        "        if self.tfm:\n",
        "            im = self.tfm(im)\n",
        "        return im, y\n",
        "\n",
        "\n",
        "def compute_class_weights(y_int, power=0.5):\n",
        "    counts = np.bincount(y_int)\n",
        "    counts[counts==0] = 1\n",
        "    w = (1.0 / counts) ** power\n",
        "    w = w / w.sum() * len(counts)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "\n",
        "def make_sampler(y_int):\n",
        "    class_count = np.bincount(y_int)\n",
        "    class_count[class_count==0] = 1\n",
        "    class_weight = 1.0 / class_count\n",
        "    sample_weight = np.array([class_weight[y] for y in y_int])\n",
        "    return WeightedRandomSampler(weights=torch.from_numpy(sample_weight).double(),\n",
        "                                 num_samples=len(sample_weight),\n",
        "                                 replacement=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "q-e8jhnnCadn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-e8jhnnCadn",
        "outputId": "15d0f036-e369-43f5-d636-48d3ba487577"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classes: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
            "Class weights: [0.807 2.443 0.796 0.603 0.723 0.726 0.901]\n"
          ]
        }
      ],
      "source": [
        "# Load CSVs\n",
        "train_df, val_df, test_df, label_to_idx, idx_to_label, COL_IMAGE, COL_LABEL = load_csvs(\n",
        "    CSV_TRAIN, CSV_VAL, CSV_TEST, COL_IMAGE, COL_LABEL\n",
        ")\n",
        "NUM_CLASSES = len(label_to_idx)\n",
        "print('Classes:', label_to_idx)\n",
        "\n",
        "# Transforms (ImageNet mean/std)\n",
        "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
        "IMAGENET_STD = [0.229, 0.224, 0.225]\n",
        "\n",
        "train_tfms = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.6, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.05),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "val_tfms = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE + 32),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD),\n",
        "])\n",
        "\n",
        "train_ds = ImageCSVDataset(train_df, img_col=COL_IMAGE, transform=train_tfms)\n",
        "val_ds   = ImageCSVDataset(val_df,   img_col=COL_IMAGE, transform=val_tfms)\n",
        "test_ds  = ImageCSVDataset(test_df,  img_col=COL_IMAGE, transform=val_tfms) if test_df is not None else None\n",
        "\n",
        "# Sampler / Loaders\n",
        "sampler = make_sampler(train_df['y'].values) if USE_SAMPLER else None\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=(sampler is None),\n",
        "                          sampler=sampler, num_workers=4, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False,\n",
        "                          num_workers=4, pin_memory=True) if test_ds is not None else None\n",
        "\n",
        "# Class weights (for CE)\n",
        "class_weights = compute_class_weights(train_df['y'].values, power=0.5).to(device)\n",
        "print('Class weights:', class_weights.cpu().numpy().round(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "wvqUQT-6Ce3G",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvqUQT-6Ce3G",
        "outputId": "0c58786c-b87b-4656-aea5-409b0c3ed9b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/lahirumunasinghe/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n",
            "100.0%\n",
            "/var/folders/zy/l_s5vzv53fz8ysl24mcw4m_h0000gn/T/ipykernel_25390/3165508055.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
            "/var/folders/zy/l_s5vzv53fz8ysl24mcw4m_h0000gn/T/ipykernel_25390/3165508055.py:24: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
          ]
        }
      ],
      "source": [
        "def build_model(num_classes):\n",
        "    # Use pretrained weights if available, else None\n",
        "    try:\n",
        "        weights = models.ResNet18_Weights.DEFAULT\n",
        "    except AttributeError:\n",
        "        weights = None\n",
        "    net = models.resnet18(weights=weights)\n",
        "    # freeze all\n",
        "    for p in net.parameters():\n",
        "        p.requires_grad = False\n",
        "    # unfreeze last block\n",
        "    for p in net.layer4.parameters():\n",
        "        p.requires_grad = True\n",
        "    in_features = net.fc.in_features\n",
        "    net.fc = nn.Linear(in_features, num_classes)\n",
        "    return net\n",
        "\n",
        "model = build_model(NUM_CLASSES).to(device)\n",
        "\n",
        "# Optimizer / Scheduler\n",
        "opt = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                        lr=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "PbbtFJAjCgTH",
      "metadata": {
        "id": "PbbtFJAjCgTH"
      },
      "outputs": [],
      "source": [
        "def mixup(images, labels, alpha=0.2):\n",
        "    if alpha <= 0.0:\n",
        "        return images, labels, labels, 1.0, False\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    index = torch.randperm(images.size(0), device=images.device)\n",
        "    mixed_x = lam * images + (1 - lam) * images[index, :]\n",
        "    y_a, y_b = labels, labels[index]\n",
        "    return mixed_x, y_a, y_b, lam, True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5P2MJj22ChDd",
      "metadata": {
        "id": "5P2MJj22ChDd"
      },
      "outputs": [],
      "source": [
        "def epoch_pass(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "    all_preds, all_tgts = [], []\n",
        "    total_loss, total_n = 0.0, 0\n",
        "\n",
        "    for ims, ys in loader:\n",
        "        ims, ys = ims.to(device), ys.to(device)\n",
        "        if train:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "            ims2, y_a, y_b, lam, used_mix = mixup(ims, ys, alpha=MIXUP_ALPHA if train else 0.0)\n",
        "            logits = model(ims2)\n",
        "            if used_mix:\n",
        "                loss = lam*F.cross_entropy(logits, y_a, weight=class_weights, label_smoothing=LABEL_SMOOTH) + \\\n",
        "                       (1-lam)*F.cross_entropy(logits, y_b, weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
        "            else:\n",
        "                loss = F.cross_entropy(logits, ys, weight=class_weights, label_smoothing=LABEL_SMOOTH)\n",
        "        if train:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(opt)\n",
        "            scaler.update()\n",
        "\n",
        "        total_loss += loss.item() * ims.size(0)\n",
        "        total_n    += ims.size(0)\n",
        "        all_preds.append(logits.detach().cpu())\n",
        "        all_tgts.append(ys.detach().cpu())\n",
        "\n",
        "    if train:\n",
        "        scheduler.step()\n",
        "\n",
        "    y_true = torch.cat(all_tgts).numpy()\n",
        "    y_pred = torch.cat(all_preds).argmax(1).numpy()\n",
        "\n",
        "    # macro-F1 (simple sklearn computation)\n",
        "    from sklearn.metrics import f1_score, accuracy_score\n",
        "    f1 = f1_score(y_true, y_pred, average='macro', zero_division=0)\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    return total_loss/total_n, f1, acc, y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "me9KEVipCjZr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "me9KEVipCjZr",
        "outputId": "679abf4d-82e0-4709-f816-a94c6d6c1442"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/lahirumunasinghe/Documents/DataScience/ann-visual-emotion/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=80, pipe_handle=94)\u001b[0m\n",
            "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mCan't get attribute 'ImageCSVDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
            "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=80, pipe_handle=94)\u001b[0m\n",
            "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
            "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
            "    exitcode = _main(fd, parent_sentinel)\n",
            "  File \u001b[35m\"/opt/homebrew/Cellar/python@3.13/3.13.2/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
            "    self = reduction.pickle.load(from_parent)\n",
            "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mCan't get attribute 'ImageCSVDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "best_f1 = 0.0\n",
        "history = []\n",
        "\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    t0 = time.time()\n",
        "    tr_loss, tr_f1, tr_acc, _, _ = epoch_pass(train_loader, train=True)\n",
        "    va_loss, va_f1, va_acc, y_true, y_pred = epoch_pass(val_loader, train=False)\n",
        "    dt = time.time()-t0\n",
        "    print(f\"Epoch {epoch:02d} | train_loss {tr_loss:.4f} F1 {tr_f1:.3f} acc {tr_acc:.3f} || val_loss {va_loss:.4f} F1 {va_f1:.3f} acc {va_acc:.3f}  [{dt:.1f}s]\")\n",
        "    history.append((epoch, tr_loss, tr_f1, tr_acc, va_loss, va_f1, va_acc))\n",
        "\n",
        "    if va_f1 > best_f1:\n",
        "        best_f1 = va_f1\n",
        "        torch.save({'model': model.state_dict(),\n",
        "                    'label_to_idx': label_to_idx,\n",
        "                    'idx_to_label': idx_to_label}, CKPT_PATH)\n",
        "        print('  -> saved best checkpoint')\n",
        "\n",
        "# Optionally unfreeze more and continue training if plateau (run again with different setup)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "077d4299",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
