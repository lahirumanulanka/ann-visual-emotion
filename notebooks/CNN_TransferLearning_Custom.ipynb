{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Custom CNN \u2014 Transfer Learning (PyTorch)\n", "*Generated on 2025-09-08 17:39*\n", "\n", "This keeps **your SimpleCNN** architecture and adds **transfer learning**:\n", "- Load weights from an older SimpleCNN checkpoint (even if channels/classes differ)\n", "- Freeze encoder initially, optionally **unfreeze later**\n", "- Conv1 **channel adapter** (1\u21943)\n", "- Strong training loop: AMP, cosine LR, early stopping, class weights"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os, math, json, random\n", "from pathlib import Path\n", "\n", "import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "\n", "import torch\n", "import torch.nn as nn\n", "import torch.nn.functional as F\n", "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n", "from torchvision import transforms as T\n", "\n", "from sklearn.metrics import classification_report, confusion_matrix\n", "from sklearn.preprocessing import LabelEncoder\n", "from tqdm.auto import tqdm\n", "\n", "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n", "print(\"Device:\", device)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Config"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Paths (edit if needed)\n", "CSV_TRAIN = \"/mnt/data/train.csv\"\n", "CSV_VAL   = \"/mnt/data/val.csv\"\n", "CSV_TEST  = \"/mnt/data/test.csv\"  # optional\n", "LABEL_MAP = \"/mnt/data/label_map.json\"\n", "IMG_ROOT  = \"\"\n", "\n", "# Columns\n", "COL_IMAGE = \"image\"\n", "COL_LABEL = \"label\"\n", "\n", "# Model\n", "IN_CHANNELS   = 3        # 1 for grayscale, 3 for RGB\n", "IMG_SIZE      = 224      # set 48 for 48x48 data\n", "BASE_CHANNELS = 32\n", "DROPOUT       = 0.3\n", "\n", "# Transfer\n", "SOURCE_CKPT   = \"\"       # e.g., \"/content/drive/MyDrive/emo_cnn_baseline_best.pt\"\n", "FREEZE_ENCODER = True\n", "UNFREEZE_AT_EPOCH = 5    # 0 = never\n", "\n", "# Training\n", "EPOCHS            = 30\n", "BATCH_SIZE        = 64\n", "LR                = 3e-4\n", "WEIGHT_DECAY      = 1e-4\n", "LABEL_SMOOTH      = 0.05\n", "USE_CLASS_WEIGHTS = True\n", "USE_WEIGHTED_SAMPLER = False\n", "USE_AMP           = True\n", "GRAD_CLIP_NORM    = 1.0\n", "EARLY_STOP        = 8\n", "\n", "OUT_DIR = \"./runs_custom_cnn_transfer\"\n", "os.makedirs(OUT_DIR, exist_ok=True)\n", "\n", "SEED = 42\n", "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data & Transforms"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from PIL import Image\n", "\n", "class CSVDataset(Dataset):\n", "    def __init__(self, csv_path, transform=None, img_root=\"\", col_img=\"image\", col_lab=\"label\", encoder=None):\n", "        self.df = pd.read_csv(csv_path)\n", "        self.transform = transform\n", "        self.img_root = img_root\n", "        self.col_img = col_img\n", "        self.col_lab = col_lab\n", "        \n", "        if encoder is None:\n", "            self.encoder = LabelEncoder().fit(self.df[self.col_lab].astype(str).values)\n", "        else:\n", "            self.encoder = encoder\n", "        self.labels = self.encoder.transform(self.df[self.col_lab].astype(str).values)\n", "        self.paths = self.df[self.col_img].astype(str).tolist()\n", "        self.n_classes = len(self.encoder.classes_)\n", "\n", "    def __len__(self): return len(self.df)\n", "\n", "    def __getitem__(self, idx):\n", "        p = self.paths[idx]\n", "        if self.img_root and not os.path.isabs(p):\n", "            p = os.path.join(self.img_root, p)\n", "        img = Image.open(p)\n", "        img = img.convert(\"RGB\") if IN_CHANNELS==3 else img.convert(\"L\")\n", "        if self.transform: img = self.transform(img)\n", "        y = self.labels[idx]\n", "        return img, y\n", "\n", "def build_transforms(img_size=224, in_ch=3):\n", "    if img_size <= 64:\n", "        train_tf = T.Compose([T.Resize((img_size,img_size)), T.RandomHorizontalFlip(0.5),\n", "                              T.ToTensor(), T.Normalize([0.5]*in_ch,[0.5]*in_ch)])\n", "        eval_tf  = T.Compose([T.Resize((img_size,img_size)), T.ToTensor(),\n", "                              T.Normalize([0.5]*in_ch,[0.5]*in_ch)])\n", "    else:\n", "        mean = [0.485,0.456,0.406][:in_ch] if in_ch==3 else [0.5]\n", "        std  = [0.229,0.224,0.225][:in_ch] if in_ch==3 else [0.5]\n", "        train_tf = T.Compose([T.Resize(int(img_size*1.1)), T.CenterCrop(img_size),\n", "                              T.RandomHorizontalFlip(0.5),\n", "                              (T.ColorJitter(0.15,0.15,0.1,0.02) if in_ch==3 else T.Lambda(lambda x:x)),\n", "                              T.ToTensor(), T.Normalize(mean, std)])\n", "        eval_tf  = T.Compose([T.Resize(int(img_size*1.1)), T.CenterCrop(img_size),\n", "                              T.ToTensor(), T.Normalize(mean, std)])\n", "    return train_tf, eval_tf\n", "\n", "def read_label_map(path):\n", "    if os.path.exists(path):\n", "        with open(path,\"r\") as f: data = json.load(f)\n", "        if isinstance(data, dict) and \"str2idx\" in data and \"idx2str\" in data:\n", "            str2idx = {k:int(v) for k,v in data[\"str2idx\"].items()}\n", "        else:\n", "            str2idx = {k:int(v) for k,v in data.items()}\n", "        classes_sorted = [k for k,_ in sorted(str2idx.items(), key=lambda kv: kv[1])]\n", "        return LabelEncoder().fit(classes_sorted)\n", "    return None\n", "\n", "train_tf, eval_tf = build_transforms(IMG_SIZE, IN_CHANNELS)\n", "enc = read_label_map(LABEL_MAP)\n", "\n", "ds_tr = CSVDataset(CSV_TRAIN, train_tf, IMG_ROOT, COL_IMAGE, COL_LABEL, enc)\n", "ds_va = CSVDataset(CSV_VAL,   eval_tf,  IMG_ROOT, COL_IMAGE, COL_LABEL, ds_tr.encoder)\n", "ds_te = CSVDataset(CSV_TEST,  eval_tf,  IMG_ROOT, COL_IMAGE, COL_LABEL, ds_tr.encoder) if os.path.exists(CSV_TEST) else None\n", "\n", "classes = list(ds_tr.encoder.classes_)\n", "num_classes = len(classes)\n", "print(\"Classes:\", classes)\n", "print(\"Sizes:\", len(ds_tr), len(ds_va), 0 if ds_te is None else len(ds_te))\n", "\n", "y_tr = ds_tr.labels\n", "class_counts = np.bincount(y_tr, minlength=num_classes).astype(float)\n", "class_weights = class_counts.sum() / (num_classes * np.maximum(class_counts, 1.0))\n", "class_weights_t = torch.tensor(class_weights, dtype=torch.float32)\n", "\n", "if USE_WEIGHTED_SAMPLER:\n", "    sample_w = class_weights[y_tr]\n", "    sampler = WeightedRandomSampler(sample_w, num_samples=len(sample_w), replacement=True)\n", "    loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n", "else:\n", "    loader_tr = DataLoader(ds_tr, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n", "\n", "loader_va = DataLoader(ds_va, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n", "loader_te = DataLoader(ds_te, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True) if ds_te else None\n", "\n", "print(\"Class counts:\", class_counts)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Custom CNN"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["class ConvBlock(nn.Module):\n", "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n", "        super().__init__()\n", "        self.conv = nn.Conv2d(in_ch, out_ch, k, s, p, bias=False)\n", "        self.bn   = nn.BatchNorm2d(out_ch)\n", "        self.act  = nn.ReLU(inplace=True)\n", "    def forward(self, x): return self.act(self.bn(self.conv(x)))\n", "\n", "class SimpleCNN(nn.Module):\n", "    def __init__(self, in_ch=3, num_classes=7, c=32, dropout=0.3):\n", "        super().__init__()\n", "        self.features = nn.Sequential(\n", "            ConvBlock(in_ch, c),   ConvBlock(c, c),   nn.MaxPool2d(2),\n", "            ConvBlock(c, 2*c),     ConvBlock(2*c,2*c),nn.MaxPool2d(2),\n", "            ConvBlock(2*c,4*c),    ConvBlock(4*c,4*c),nn.MaxPool2d(2),\n", "            ConvBlock(4*c,8*c),    ConvBlock(8*c,8*c),nn.MaxPool2d(2),\n", "        )\n", "        self.head = nn.Sequential(\n", "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n", "            nn.Dropout(dropout),\n", "            nn.Linear(8*c, num_classes)\n", "        )\n", "    def forward(self, x): return self.head(self.features(x))\n", "\n", "def build_model(in_ch, n_classes, c=32, dropout=0.3):\n", "    return SimpleCNN(in_ch, n_classes, c, dropout)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Transfer loader (partial load + conv1 adapter)"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def adapt_conv1(w, target_in_ch):\n", "    out_ch, in_ch, k1, k2 = w.shape\n", "    if in_ch == target_in_ch: return w\n", "    if in_ch == 1 and target_in_ch == 3:\n", "        return w.repeat(1,3,1,1)  # replicate gray to RGB\n", "    if in_ch == 3 and target_in_ch == 1:\n", "        return w.mean(dim=1, keepdim=True)\n", "    # generic tile/trim\n", "    if target_in_ch > in_ch:\n", "        reps = (target_in_ch + in_ch - 1)//in_ch\n", "        w2 = w.repeat(1,reps,1,1)[:, :target_in_ch, :, :]\n", "        return w2 * (in_ch/target_in_ch)\n", "    else:\n", "        return w[:, :target_in_ch, :, :]\n", "\n", "def load_for_transfer(model, ckpt_path, in_ch_target):\n", "    if not ckpt_path or not os.path.exists(ckpt_path):\n", "        print(\"No SOURCE_CKPT -> training from scratch.\"); return\n", "    state = torch.load(ckpt_path, map_location=\"cpu\")\n", "    sd = state.get(\"model\", state)\n", "    msd = model.state_dict()\n", "    loaded = 0\n", "    for k,v in sd.items():\n", "        if k in msd and msd[k].shape == v.shape:\n", "            msd[k] = v; loaded += 1\n", "        elif k.endswith(\"features.0.conv.weight\") and \"features.0.conv.weight\" in msd:\n", "            v2 = adapt_conv1(v, in_ch_target)\n", "            if msd[\"features.0.conv.weight\"].shape == v2.shape:\n", "                msd[\"features.0.conv.weight\"] = v2; loaded += 1\n", "    model.load_state_dict(msd, strict=False)\n", "    print(f\"Loaded {loaded} tensors from {ckpt_path}\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train setup"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["model = build_model(IN_CHANNELS, num_classes, c=BASE_CHANNELS, dropout=DROPOUT).to(device)\n", "load_for_transfer(model, SOURCE_CKPT, IN_CHANNELS)\n", "\n", "# Freeze encoder\n", "def set_encoder_trainable(net, flag: bool):\n", "    for p in net.features.parameters():\n", "        p.requires_grad = flag\n", "\n", "if FREEZE_ENCODER:\n", "    set_encoder_trainable(model, False)\n", "    print(\"Encoder frozen. Will unfreeze at epoch:\", UNFREEZE_AT_EPOCH if UNFREEZE_AT_EPOCH>0 else \"never\")\n", "\n", "class LabelSmoothingCE(nn.Module):\n", "    def __init__(self, smoothing=0.0, weight=None):\n", "        super().__init__()\n", "        self.smoothing = smoothing\n", "        self.weight = weight\n", "    def forward(self, logits, target):\n", "        n = logits.size(-1)\n", "        logp = F.log_softmax(logits, dim=-1)\n", "        with torch.no_grad():\n", "            true = torch.zeros_like(logp)\n", "            true.fill_(self.smoothing / (n-1))\n", "            true.scatter_(1, target.unsqueeze(1), 1-self.smoothing)\n", "        if self.weight is not None:\n", "            w = self.weight.unsqueeze(0)\n", "            loss = -(true*logp*w).sum(dim=1)\n", "        else:\n", "            loss = -(true*logp).sum(dim=1)\n", "        return loss.mean()\n", "\n", "criterion = LabelSmoothingCE(LABEL_SMOOTH, class_weights_t.to(device) if USE_CLASS_WEIGHTS else None)\n", "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n", "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n", "scaler = torch.cuda.amp.GradScaler() if (USE_AMP and device.type=='cuda') else None\n", "\n", "def acc(logits, y): return (logits.argmax(1)==y).float().mean().item()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train/Eval loops"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["@torch.no_grad()\n", "def evaluate(net, loader):\n", "    net.eval(); losses=[]; accs=[]; y_true=[]; y_pred=[]\n", "    for x,y in tqdm(loader, desc=\"Eval\", leave=False):\n", "        x=x.to(device,non_blocking=True); y=y.to(device,non_blocking=True)\n", "        logits = net(x); loss = criterion(logits, y)\n", "        losses.append(loss.item()); accs.append(acc(logits,y))\n", "        y_true += y.cpu().tolist(); y_pred += logits.argmax(1).cpu().tolist()\n", "    return float(np.mean(losses)), float(np.mean(accs)), np.array(y_true), np.array(y_pred)\n", "\n", "def train_one_epoch(net, loader, opt, scaler=None):\n", "    net.train(); losses=[]; accs=[]\n", "    for x,y in tqdm(loader, desc=\"Train\", leave=False):\n", "        x=x.to(device,non_blocking=True); y=y.to(device,non_blocking=True)\n", "        opt.zero_grad(set_to_none=True)\n", "        if scaler is not None:\n", "            with torch.cuda.amp.autocast():\n", "                logits = net(x); loss = criterion(logits, y)\n", "            scaler.scale(loss).backward()\n", "            if GRAD_CLIP_NORM>0:\n", "                scaler.unscale_(opt); nn.utils.clip_grad_norm_(net.parameters(), GRAD_CLIP_NORM)\n", "            scaler.step(opt); scaler.update()\n", "        else:\n", "            logits = net(x); loss = criterion(logits, y)\n", "            loss.backward()\n", "            if GRAD_CLIP_NORM>0: nn.utils.clip_grad_norm_(net.parameters(), GRAD_CLIP_NORM)\n", "            opt.step()\n", "        losses.append(loss.item()); accs.append(acc(logits,y))\n", "    return float(np.mean(losses)), float(np.mean(accs))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Train"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["best_acc=-1.0; noimp=0\n", "ckpt = os.path.join(OUT_DIR,\"custom_cnn_best.pt\")\n", "hist={\"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n", "\n", "for epoch in range(EPOCHS):\n", "    if FREEZE_ENCODER and UNFREEZE_AT_EPOCH>0 and epoch==UNFREEZE_AT_EPOCH:\n", "        set_encoder_trainable(model, True)\n", "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n", "        print(f\"\ud83d\udd13 Unfroze encoder at epoch {epoch}\")\n", "    tr_loss,tr_acc = train_one_epoch(model, loader_tr, optimizer, scaler)\n", "    scheduler.step()\n", "    va_loss,va_acc,y_true,y_pred = evaluate(model, loader_va)\n", "\n", "    hist[\"train_loss\"].append(tr_loss); hist[\"train_acc\"].append(tr_acc)\n", "    hist[\"val_loss\"].append(va_loss);   hist[\"val_acc\"].append(va_acc)\n", "\n", "    print(f\"Epoch {epoch+1:02d} | train {tr_loss:.4f}/{tr_acc:.4f}  val {va_loss:.4f}/{va_acc:.4f}\")\n", "    if va_acc>best_acc:\n", "        best_acc=va_acc; noimp=0\n", "        torch.save({\"model\":model.state_dict(), \"in_channels\":IN_CHANNELS, \"classes\":classes,\n", "                    \"arch\":{\"base_channels\":BASE_CHANNELS,\"dropout\":DROPOUT}}, ckpt)\n", "        print(\"  \u2705 Saved:\", ckpt)\n", "    else:\n", "        noimp+=1\n", "        if noimp>=EARLY_STOP:\n", "            print(\"\u23f9\ufe0f Early stopping\"); break\n", "\n", "# plots\n", "plt.figure(figsize=(6,4)); plt.plot(hist[\"train_acc\"],label=\"train_acc\"); plt.plot(hist[\"val_acc\"],label=\"val_acc\"); plt.legend(); plt.title(\"Accuracy\"); plt.show()\n", "plt.figure(figsize=(6,4)); plt.plot(hist[\"train_loss\"],label=\"train_loss\"); plt.plot(hist[\"val_loss\"],label=\"val_loss\"); plt.legend(); plt.title(\"Loss\"); plt.show()\n", "\n", "# Final eval (best)\n", "state = torch.load(ckpt, map_location=device)\n", "model = SimpleCNN(in_ch=state[\"in_channels\"], num_classes=len(state[\"classes\"]),\n", "                  c=state[\"arch\"][\"base_channels\"], dropout=state[\"arch\"][\"dropout\"]).to(device)\n", "model.load_state_dict(state[\"model\"])\n", "\n", "_, va_acc, y_true, y_pred = evaluate(model, loader_va)\n", "print(\"Best Val Acc:\", va_acc)\n", "print(\"\\nClassification Report (Val):\")\n", "print(classification_report(y_true, y_pred, target_names=classes, digits=4))\n", "\n", "cm = confusion_matrix(y_true, y_pred, labels=list(range(len(classes))))\n", "plt.figure(figsize=(6,6)); plt.imshow(cm, interpolation=\"nearest\"); plt.title(\"Confusion Matrix (Val)\"); plt.colorbar()\n", "ticks=np.arange(len(classes)); plt.xticks(ticks, classes, rotation=45, ha=\"right\"); plt.yticks(ticks, classes)\n", "plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout(); plt.show()\n", "\n", "if loader_te is not None:\n", "    _, te_acc, y_true_te, y_pred_te = evaluate(model, loader_te)\n", "    print(\"\\nTest Acc:\", te_acc)\n", "    print(\"\\nClassification Report (Test):\")\n", "    print(classification_report(y_true_te, y_pred_te, target_names=classes, digits=4))"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Inference helper"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["from PIL import Image\n", "def build_infer_transform(img_size, in_ch):\n", "    if img_size<=64:\n", "        mean=[0.5]*in_ch; std=[0.5]*in_ch\n", "        return T.Compose([T.Resize((img_size,img_size)), T.ToTensor(), T.Normalize(mean,std)])\n", "    else:\n", "        if in_ch==3:\n", "            mean=[0.485,0.456,0.406]; std=[0.229,0.224,0.225]\n", "        else:\n", "            mean=[0.5]; std=[0.5]\n", "        return T.Compose([T.Resize(int(img_size*1.1)), T.CenterCrop(img_size), T.ToTensor(), T.Normalize(mean,std)])\n", "\n", "@torch.no_grad()\n", "def predict_image(path, ckpt_path, topk=5):\n", "    st = torch.load(ckpt_path, map_location=device)\n", "    net = SimpleCNN(in_ch=st[\"in_channels\"], num_classes=len(st[\"classes\"]),\n", "                    c=st[\"arch\"][\"base_channels\"], dropout=st[\"arch\"][\"dropout\"]).to(device)\n", "    net.load_state_dict(st[\"model\"]); net.eval()\n", "    img = Image.open(path)\n", "    img = img.convert(\"RGB\") if st[\"in_channels\"]==3 else img.convert(\"L\")\n", "    tfm = build_infer_transform(IMG_SIZE, st[\"in_channels\"])\n", "    x = tfm(img).unsqueeze(0).to(device)\n", "    logits = net(x); probs = logits.softmax(1).cpu().numpy().squeeze()\n", "    order = probs.argsort()[::-1][:topk]\n", "    return [(st[\"classes\"][i], float(probs[i])) for i in order]\n", "\n", "# Example:\n", "# predict_image(\"/path/to/img.jpg\", ckpt)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}